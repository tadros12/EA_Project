{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 19:42:40.014005: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747154560.028422   41146 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747154560.032339   41146 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-13 19:42:40.048340: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import boston_housing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()\n",
    "\n",
    "train_labels_one_hot = tf.keras.utils.to_categorical(train_labels, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747154562.935547   41146 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2169 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(32, activation=\"sigmoid\"),\n",
    "\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"SGD\",\n",
    "              loss=\"categorical_crossentropy\",  # Changed from sparse_categorical_crossentropy\n",
    "              metrics=[\"accuracy\", \"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747154563.892762   41247 service.cc:148] XLA service 0x7f4f58016420 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747154563.892792   41247 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-05-13 19:42:43.904037: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1747154563.935662   41247 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/469\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1365 - loss: 2.3984 - mse: 0.0920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747154565.737860   41247 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.2678 - loss: 2.2436 - mse: 0.0885\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6317 - loss: 1.7908 - mse: 0.0765\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7124 - loss: 1.4778 - mse: 0.0652\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7539 - loss: 1.2422 - mse: 0.0555\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7874 - loss: 1.0694 - mse: 0.0479\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8074 - loss: 0.9409 - mse: 0.0421\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8236 - loss: 0.8479 - mse: 0.0377\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8347 - loss: 0.7730 - mse: 0.0342\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8471 - loss: 0.7066 - mse: 0.0310\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8533 - loss: 0.6606 - mse: 0.0289\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels_one_hot, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 3ms/step - accuracy: 0.8653 - loss: 0.6129 - mse: 0.0266\n",
      "Test loss: 0.6129303574562073\n",
      "Test accuracy: 0.8652999997138977\n",
      "Test MSE: 0.02664114162325859\n"
     ]
    }
   ],
   "source": [
    "test_labels_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_results = model.evaluate(test_images, test_labels_one_hot, verbose=2)\n",
    "\n",
    "print(f\"Test loss: {test_results[0]}\")\n",
    "print(f\"Test accuracy: {test_results[1]}\")\n",
    "print(f\"Test MSE: {test_results[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape before normalization: (404, 13)\n",
      "y_train shape: (404,)\n",
      "x_train shape after normalization and conversion: (404, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "print(\"x_train shape before normalization:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "mean = x_train.mean(axis=0)\n",
    "std = x_train.std(axis=0)\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std\n",
    "\n",
    "x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "x_test = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "\n",
    "print(\"x_train shape after normalization and conversion:\", x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "26/26 - 1s - 42ms/step - loss: 112.9712 - mae: 6.9628 - mse: 112.9712 - val_loss: 27.3403 - val_mae: 4.0432 - val_mse: 27.3403\n",
      "Epoch 2/200\n",
      "26/26 - 0s - 4ms/step - loss: 29.6415 - mae: 3.7084 - mse: 29.6415 - val_loss: 23.6868 - val_mae: 3.7569 - val_mse: 23.6868\n",
      "Epoch 3/200\n",
      "26/26 - 0s - 4ms/step - loss: 26.1181 - mae: 3.4966 - mse: 26.1181 - val_loss: 21.4072 - val_mae: 3.4054 - val_mse: 21.4072\n",
      "Epoch 4/200\n",
      "26/26 - 0s - 4ms/step - loss: 24.6080 - mae: 3.3859 - mse: 24.6080 - val_loss: 21.7118 - val_mae: 3.3509 - val_mse: 21.7118\n",
      "Epoch 5/200\n",
      "26/26 - 0s - 4ms/step - loss: 23.5760 - mae: 3.3597 - mse: 23.5760 - val_loss: 22.9697 - val_mae: 3.4348 - val_mse: 22.9697\n",
      "Epoch 6/200\n",
      "26/26 - 0s - 4ms/step - loss: 22.5353 - mae: 3.3218 - mse: 22.5353 - val_loss: 22.7805 - val_mae: 3.5670 - val_mse: 22.7805\n",
      "Epoch 7/200\n",
      "26/26 - 0s - 4ms/step - loss: 21.7141 - mae: 3.3730 - mse: 21.7141 - val_loss: 23.9850 - val_mae: 3.4802 - val_mse: 23.9850\n",
      "Epoch 8/200\n",
      "26/26 - 0s - 4ms/step - loss: 21.0333 - mae: 3.2083 - mse: 21.0333 - val_loss: 21.3912 - val_mae: 3.5384 - val_mse: 21.3912\n",
      "Epoch 9/200\n",
      "26/26 - 0s - 4ms/step - loss: 20.9449 - mae: 3.2552 - mse: 20.9449 - val_loss: 23.1337 - val_mae: 3.5433 - val_mse: 23.1337\n",
      "Epoch 10/200\n",
      "26/26 - 0s - 4ms/step - loss: 20.0510 - mae: 3.1683 - mse: 20.0510 - val_loss: 20.7954 - val_mae: 3.3394 - val_mse: 20.7954\n",
      "Epoch 11/200\n",
      "26/26 - 0s - 4ms/step - loss: 19.2292 - mae: 3.1268 - mse: 19.2292 - val_loss: 21.0887 - val_mae: 3.3918 - val_mse: 21.0887\n",
      "Epoch 12/200\n",
      "26/26 - 0s - 4ms/step - loss: 18.8172 - mae: 3.1185 - mse: 18.8172 - val_loss: 21.5322 - val_mae: 3.2908 - val_mse: 21.5322\n",
      "Epoch 13/200\n",
      "26/26 - 0s - 4ms/step - loss: 18.4848 - mae: 3.0123 - mse: 18.4848 - val_loss: 21.4592 - val_mae: 3.3430 - val_mse: 21.4592\n",
      "Epoch 14/200\n",
      "26/26 - 0s - 4ms/step - loss: 17.7514 - mae: 3.0141 - mse: 17.7514 - val_loss: 20.9714 - val_mae: 3.3497 - val_mse: 20.9714\n",
      "Epoch 15/200\n",
      "26/26 - 0s - 4ms/step - loss: 17.2813 - mae: 2.9849 - mse: 17.2813 - val_loss: 22.3644 - val_mae: 3.3341 - val_mse: 22.3644\n",
      "Epoch 16/200\n",
      "26/26 - 0s - 4ms/step - loss: 16.9216 - mae: 2.9433 - mse: 16.9216 - val_loss: 20.4218 - val_mae: 3.2385 - val_mse: 20.4218\n",
      "Epoch 17/200\n",
      "26/26 - 0s - 4ms/step - loss: 16.1596 - mae: 2.9326 - mse: 16.1596 - val_loss: 23.9793 - val_mae: 3.4665 - val_mse: 23.9793\n",
      "Epoch 18/200\n",
      "26/26 - 0s - 4ms/step - loss: 16.1812 - mae: 2.8078 - mse: 16.1812 - val_loss: 22.9786 - val_mae: 3.3851 - val_mse: 22.9786\n",
      "Epoch 19/200\n",
      "26/26 - 0s - 4ms/step - loss: 15.1447 - mae: 2.8058 - mse: 15.1447 - val_loss: 20.7838 - val_mae: 3.1758 - val_mse: 20.7838\n",
      "Epoch 20/200\n",
      "26/26 - 0s - 4ms/step - loss: 15.6130 - mae: 2.8329 - mse: 15.6130 - val_loss: 21.4711 - val_mae: 3.2204 - val_mse: 21.4711\n",
      "Epoch 21/200\n",
      "26/26 - 0s - 4ms/step - loss: 14.5904 - mae: 2.7283 - mse: 14.5904 - val_loss: 24.0111 - val_mae: 3.4210 - val_mse: 24.0111\n",
      "Epoch 22/200\n",
      "26/26 - 0s - 4ms/step - loss: 14.2813 - mae: 2.6856 - mse: 14.2813 - val_loss: 24.3449 - val_mae: 3.3854 - val_mse: 24.3449\n",
      "Epoch 23/200\n",
      "26/26 - 0s - 4ms/step - loss: 14.0131 - mae: 2.6489 - mse: 14.0131 - val_loss: 22.0247 - val_mae: 3.3171 - val_mse: 22.0247\n",
      "Epoch 24/200\n",
      "26/26 - 0s - 4ms/step - loss: 13.4676 - mae: 2.6521 - mse: 13.4676 - val_loss: 25.2727 - val_mae: 3.4769 - val_mse: 25.2727\n",
      "Epoch 25/200\n",
      "26/26 - 0s - 4ms/step - loss: 12.7666 - mae: 2.6093 - mse: 12.7666 - val_loss: 19.8642 - val_mae: 3.0329 - val_mse: 19.8642\n",
      "Epoch 26/200\n",
      "26/26 - 0s - 4ms/step - loss: 13.0649 - mae: 2.5641 - mse: 13.0649 - val_loss: 20.8988 - val_mae: 3.1216 - val_mse: 20.8988\n",
      "Epoch 27/200\n",
      "26/26 - 0s - 4ms/step - loss: 12.3498 - mae: 2.5164 - mse: 12.3498 - val_loss: 19.9701 - val_mae: 3.0486 - val_mse: 19.9701\n",
      "Epoch 28/200\n",
      "26/26 - 0s - 4ms/step - loss: 12.2829 - mae: 2.5037 - mse: 12.2829 - val_loss: 22.0603 - val_mae: 3.1444 - val_mse: 22.0603\n",
      "Epoch 29/200\n",
      "26/26 - 0s - 4ms/step - loss: 11.7591 - mae: 2.4465 - mse: 11.7591 - val_loss: 22.4921 - val_mae: 3.1484 - val_mse: 22.4921\n",
      "Epoch 30/200\n",
      "26/26 - 0s - 4ms/step - loss: 11.7013 - mae: 2.4712 - mse: 11.7013 - val_loss: 20.9068 - val_mae: 3.0469 - val_mse: 20.9068\n",
      "Epoch 31/200\n",
      "26/26 - 0s - 4ms/step - loss: 11.7152 - mae: 2.4525 - mse: 11.7152 - val_loss: 21.2469 - val_mae: 3.0495 - val_mse: 21.2469\n",
      "Epoch 32/200\n",
      "26/26 - 0s - 4ms/step - loss: 11.2591 - mae: 2.3896 - mse: 11.2591 - val_loss: 22.7466 - val_mae: 3.1422 - val_mse: 22.7466\n",
      "Epoch 33/200\n",
      "26/26 - 0s - 4ms/step - loss: 11.0260 - mae: 2.4040 - mse: 11.0260 - val_loss: 25.7451 - val_mae: 3.4646 - val_mse: 25.7451\n",
      "Epoch 34/200\n",
      "26/26 - 0s - 5ms/step - loss: 10.7879 - mae: 2.3652 - mse: 10.7879 - val_loss: 27.5650 - val_mae: 3.5488 - val_mse: 27.5650\n",
      "Epoch 35/200\n",
      "26/26 - 0s - 4ms/step - loss: 10.6166 - mae: 2.2805 - mse: 10.6166 - val_loss: 20.9058 - val_mae: 3.0686 - val_mse: 20.9058\n",
      "Epoch 36/200\n",
      "26/26 - 0s - 4ms/step - loss: 10.5000 - mae: 2.3219 - mse: 10.5000 - val_loss: 21.1774 - val_mae: 3.0035 - val_mse: 21.1774\n",
      "Epoch 37/200\n",
      "26/26 - 0s - 4ms/step - loss: 10.1875 - mae: 2.2894 - mse: 10.1875 - val_loss: 22.0347 - val_mae: 3.0979 - val_mse: 22.0347\n",
      "Epoch 38/200\n",
      "26/26 - 0s - 4ms/step - loss: 10.2666 - mae: 2.3260 - mse: 10.2666 - val_loss: 20.1248 - val_mae: 2.9373 - val_mse: 20.1248\n",
      "Epoch 39/200\n",
      "26/26 - 0s - 4ms/step - loss: 10.1211 - mae: 2.2902 - mse: 10.1211 - val_loss: 20.9199 - val_mae: 2.9476 - val_mse: 20.9199\n",
      "Epoch 40/200\n",
      "26/26 - 0s - 4ms/step - loss: 9.8371 - mae: 2.2412 - mse: 9.8371 - val_loss: 19.4960 - val_mae: 2.9606 - val_mse: 19.4960\n",
      "Epoch 41/200\n",
      "26/26 - 0s - 4ms/step - loss: 9.8833 - mae: 2.2695 - mse: 9.8833 - val_loss: 17.9245 - val_mae: 2.7964 - val_mse: 17.9245\n",
      "Epoch 42/200\n",
      "26/26 - 0s - 4ms/step - loss: 9.6994 - mae: 2.2295 - mse: 9.6994 - val_loss: 20.3514 - val_mae: 2.9041 - val_mse: 20.3514\n",
      "Epoch 43/200\n",
      "26/26 - 0s - 4ms/step - loss: 9.6189 - mae: 2.1950 - mse: 9.6189 - val_loss: 22.3697 - val_mae: 3.0818 - val_mse: 22.3697\n",
      "Epoch 44/200\n",
      "26/26 - 0s - 4ms/step - loss: 9.2410 - mae: 2.1568 - mse: 9.2410 - val_loss: 22.4417 - val_mae: 3.0359 - val_mse: 22.4417\n",
      "Epoch 45/200\n",
      "26/26 - 0s - 4ms/step - loss: 9.2572 - mae: 2.1889 - mse: 9.2572 - val_loss: 21.3551 - val_mae: 2.9623 - val_mse: 21.3551\n",
      "Epoch 46/200\n",
      "26/26 - 0s - 5ms/step - loss: 8.8654 - mae: 2.1200 - mse: 8.8654 - val_loss: 22.0783 - val_mae: 3.0218 - val_mse: 22.0783\n",
      "Epoch 47/200\n",
      "26/26 - 0s - 4ms/step - loss: 9.2201 - mae: 2.2007 - mse: 9.2201 - val_loss: 20.0496 - val_mae: 2.8975 - val_mse: 20.0496\n",
      "Epoch 48/200\n",
      "26/26 - 0s - 4ms/step - loss: 9.2285 - mae: 2.1787 - mse: 9.2285 - val_loss: 21.7610 - val_mae: 3.0773 - val_mse: 21.7610\n",
      "Epoch 49/200\n",
      "26/26 - 0s - 4ms/step - loss: 8.9180 - mae: 2.1628 - mse: 8.9180 - val_loss: 19.9858 - val_mae: 3.0188 - val_mse: 19.9858\n",
      "Epoch 50/200\n",
      "26/26 - 0s - 4ms/step - loss: 8.8159 - mae: 2.1471 - mse: 8.8159 - val_loss: 23.5313 - val_mae: 3.1225 - val_mse: 23.5313\n",
      "Epoch 51/200\n",
      "26/26 - 0s - 4ms/step - loss: 9.1595 - mae: 2.1859 - mse: 9.1595 - val_loss: 22.1420 - val_mae: 3.0165 - val_mse: 22.1420\n",
      "Epoch 52/200\n",
      "26/26 - 0s - 4ms/step - loss: 8.8266 - mae: 2.1098 - mse: 8.8266 - val_loss: 22.3111 - val_mae: 3.0303 - val_mse: 22.3111\n",
      "Epoch 53/200\n",
      "26/26 - 0s - 4ms/step - loss: 8.5585 - mae: 2.0957 - mse: 8.5585 - val_loss: 19.6097 - val_mae: 2.8525 - val_mse: 19.6097\n",
      "Epoch 54/200\n",
      "26/26 - 0s - 4ms/step - loss: 8.4375 - mae: 2.0827 - mse: 8.4375 - val_loss: 20.6788 - val_mae: 2.9299 - val_mse: 20.6788\n",
      "Epoch 55/200\n",
      "26/26 - 0s - 4ms/step - loss: 8.4539 - mae: 2.0820 - mse: 8.4539 - val_loss: 20.4896 - val_mae: 2.9013 - val_mse: 20.4896\n",
      "Epoch 56/200\n",
      "26/26 - 0s - 5ms/step - loss: 8.2068 - mae: 2.0517 - mse: 8.2068 - val_loss: 20.3943 - val_mae: 2.8934 - val_mse: 20.3943\n",
      "Epoch 57/200\n",
      "26/26 - 0s - 4ms/step - loss: 8.2778 - mae: 2.0803 - mse: 8.2778 - val_loss: 24.8932 - val_mae: 3.4308 - val_mse: 24.8932\n",
      "Epoch 58/200\n",
      "26/26 - 0s - 4ms/step - loss: 8.4311 - mae: 2.0817 - mse: 8.4311 - val_loss: 21.8441 - val_mae: 3.0121 - val_mse: 21.8441\n",
      "Epoch 59/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.9750 - mae: 2.0451 - mse: 7.9750 - val_loss: 19.4686 - val_mae: 2.8443 - val_mse: 19.4686\n",
      "Epoch 60/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.9109 - mae: 2.0530 - mse: 7.9109 - val_loss: 20.6314 - val_mae: 2.9053 - val_mse: 20.6314\n",
      "Epoch 61/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.9848 - mae: 2.0262 - mse: 7.9848 - val_loss: 24.5980 - val_mae: 3.3562 - val_mse: 24.5980\n",
      "Epoch 62/200\n",
      "26/26 - 0s - 4ms/step - loss: 8.1376 - mae: 2.0459 - mse: 8.1376 - val_loss: 21.9058 - val_mae: 2.9823 - val_mse: 21.9058\n",
      "Epoch 63/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.8888 - mae: 2.0206 - mse: 7.8888 - val_loss: 35.7167 - val_mae: 3.8006 - val_mse: 35.7167\n",
      "Epoch 64/200\n",
      "26/26 - 0s - 4ms/step - loss: 8.5165 - mae: 2.0935 - mse: 8.5165 - val_loss: 34.9211 - val_mae: 3.9159 - val_mse: 34.9211\n",
      "Epoch 65/200\n",
      "26/26 - 0s - 4ms/step - loss: 8.2566 - mae: 2.0945 - mse: 8.2566 - val_loss: 20.9932 - val_mae: 2.9555 - val_mse: 20.9932\n",
      "Epoch 66/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.7851 - mae: 2.0061 - mse: 7.7851 - val_loss: 22.7552 - val_mae: 3.1876 - val_mse: 22.7552\n",
      "Epoch 67/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.5613 - mae: 1.9757 - mse: 7.5613 - val_loss: 21.0939 - val_mae: 2.9501 - val_mse: 21.0939\n",
      "Epoch 68/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.6964 - mae: 1.9980 - mse: 7.6964 - val_loss: 21.9967 - val_mae: 3.0194 - val_mse: 21.9967\n",
      "Epoch 69/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.6492 - mae: 2.0170 - mse: 7.6492 - val_loss: 21.0105 - val_mae: 2.9403 - val_mse: 21.0105\n",
      "Epoch 70/200\n",
      "26/26 - 0s - 5ms/step - loss: 7.4633 - mae: 1.9622 - mse: 7.4633 - val_loss: 21.4905 - val_mae: 2.9780 - val_mse: 21.4905\n",
      "Epoch 71/200\n",
      "26/26 - 0s - 5ms/step - loss: 7.4172 - mae: 1.9724 - mse: 7.4172 - val_loss: 20.2854 - val_mae: 2.9236 - val_mse: 20.2854\n",
      "Epoch 72/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.3831 - mae: 1.9597 - mse: 7.3831 - val_loss: 18.4659 - val_mae: 2.8353 - val_mse: 18.4659\n",
      "Epoch 73/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.6904 - mae: 1.9751 - mse: 7.6904 - val_loss: 19.4955 - val_mae: 2.8416 - val_mse: 19.4955\n",
      "Epoch 74/200\n",
      "26/26 - 0s - 5ms/step - loss: 7.3289 - mae: 1.9725 - mse: 7.3289 - val_loss: 20.2727 - val_mae: 2.8778 - val_mse: 20.2727\n",
      "Epoch 75/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.1478 - mae: 1.9511 - mse: 7.1478 - val_loss: 21.2019 - val_mae: 3.0181 - val_mse: 21.2019\n",
      "Epoch 76/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.2045 - mae: 1.9453 - mse: 7.2045 - val_loss: 21.1309 - val_mae: 3.0122 - val_mse: 21.1309\n",
      "Epoch 77/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.1170 - mae: 1.9347 - mse: 7.1170 - val_loss: 20.8761 - val_mae: 2.9440 - val_mse: 20.8761\n",
      "Epoch 78/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.1432 - mae: 1.9328 - mse: 7.1432 - val_loss: 19.2454 - val_mae: 2.8067 - val_mse: 19.2454\n",
      "Epoch 79/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.1323 - mae: 1.9458 - mse: 7.1323 - val_loss: 19.8410 - val_mae: 2.8582 - val_mse: 19.8410\n",
      "Epoch 80/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.1840 - mae: 1.9197 - mse: 7.1840 - val_loss: 18.8944 - val_mae: 2.7919 - val_mse: 18.8944\n",
      "Epoch 81/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.0775 - mae: 1.9068 - mse: 7.0775 - val_loss: 21.3915 - val_mae: 3.0020 - val_mse: 21.3915\n",
      "Epoch 82/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.9511 - mae: 1.9108 - mse: 6.9511 - val_loss: 20.7142 - val_mae: 2.9380 - val_mse: 20.7142\n",
      "Epoch 83/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.8863 - mae: 1.8921 - mse: 6.8863 - val_loss: 19.0816 - val_mae: 2.8037 - val_mse: 19.0816\n",
      "Epoch 84/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.9745 - mae: 1.9266 - mse: 6.9745 - val_loss: 20.8768 - val_mae: 2.9749 - val_mse: 20.8768\n",
      "Epoch 85/200\n",
      "26/26 - 0s - 6ms/step - loss: 6.9474 - mae: 1.8941 - mse: 6.9474 - val_loss: 19.5454 - val_mae: 2.8155 - val_mse: 19.5454\n",
      "Epoch 86/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.7744 - mae: 1.8813 - mse: 6.7744 - val_loss: 20.3169 - val_mae: 2.9439 - val_mse: 20.3169\n",
      "Epoch 87/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.9091 - mae: 1.8853 - mse: 6.9091 - val_loss: 18.6508 - val_mae: 2.7844 - val_mse: 18.6508\n",
      "Epoch 88/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.7846 - mae: 1.9089 - mse: 6.7846 - val_loss: 18.4812 - val_mae: 2.7915 - val_mse: 18.4812\n",
      "Epoch 89/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.8631 - mae: 1.8835 - mse: 6.8631 - val_loss: 18.7411 - val_mae: 2.7789 - val_mse: 18.7411\n",
      "Epoch 90/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.7767 - mae: 1.8859 - mse: 6.7767 - val_loss: 27.1210 - val_mae: 3.4593 - val_mse: 27.1210\n",
      "Epoch 91/200\n",
      "26/26 - 0s - 4ms/step - loss: 7.2070 - mae: 1.9527 - mse: 7.2070 - val_loss: 20.4542 - val_mae: 2.8982 - val_mse: 20.4542\n",
      "Epoch 92/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.5348 - mae: 1.8592 - mse: 6.5348 - val_loss: 19.7814 - val_mae: 2.8636 - val_mse: 19.7814\n",
      "Epoch 93/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.5623 - mae: 1.8420 - mse: 6.5623 - val_loss: 19.0401 - val_mae: 2.7846 - val_mse: 19.0401\n",
      "Epoch 94/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.5872 - mae: 1.8376 - mse: 6.5872 - val_loss: 17.7650 - val_mae: 2.6945 - val_mse: 17.7650\n",
      "Epoch 95/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.4156 - mae: 1.8348 - mse: 6.4156 - val_loss: 20.5282 - val_mae: 2.9807 - val_mse: 20.5282\n",
      "Epoch 96/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.5677 - mae: 1.8638 - mse: 6.5677 - val_loss: 19.5453 - val_mae: 2.8861 - val_mse: 19.5453\n",
      "Epoch 97/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.4583 - mae: 1.8355 - mse: 6.4583 - val_loss: 18.7335 - val_mae: 2.7865 - val_mse: 18.7335\n",
      "Epoch 98/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.3766 - mae: 1.8216 - mse: 6.3766 - val_loss: 19.6703 - val_mae: 2.8783 - val_mse: 19.6703\n",
      "Epoch 99/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.6073 - mae: 1.8606 - mse: 6.6073 - val_loss: 18.7506 - val_mae: 2.7851 - val_mse: 18.7506\n",
      "Epoch 100/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.2873 - mae: 1.8165 - mse: 6.2873 - val_loss: 19.4051 - val_mae: 2.8837 - val_mse: 19.4051\n",
      "Epoch 101/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.4125 - mae: 1.8262 - mse: 6.4125 - val_loss: 18.3133 - val_mae: 2.7442 - val_mse: 18.3133\n",
      "Epoch 102/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.4215 - mae: 1.8436 - mse: 6.4215 - val_loss: 18.9275 - val_mae: 2.8013 - val_mse: 18.9275\n",
      "Epoch 103/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.2643 - mae: 1.8088 - mse: 6.2643 - val_loss: 18.2315 - val_mae: 2.7332 - val_mse: 18.2315\n",
      "Epoch 104/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.2741 - mae: 1.8117 - mse: 6.2741 - val_loss: 19.0965 - val_mae: 2.8099 - val_mse: 19.0965\n",
      "Epoch 105/200\n",
      "26/26 - 0s - 5ms/step - loss: 6.2229 - mae: 1.7978 - mse: 6.2229 - val_loss: 18.5064 - val_mae: 2.7577 - val_mse: 18.5064\n",
      "Epoch 106/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.1711 - mae: 1.7938 - mse: 6.1711 - val_loss: 17.0837 - val_mae: 2.6639 - val_mse: 17.0837\n",
      "Epoch 107/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.2938 - mae: 1.8005 - mse: 6.2938 - val_loss: 19.4275 - val_mae: 2.9216 - val_mse: 19.4275\n",
      "Epoch 108/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.2878 - mae: 1.8189 - mse: 6.2878 - val_loss: 17.7900 - val_mae: 2.7242 - val_mse: 17.7900\n",
      "Epoch 109/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.1241 - mae: 1.7739 - mse: 6.1241 - val_loss: 17.5042 - val_mae: 2.6975 - val_mse: 17.5042\n",
      "Epoch 110/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.2072 - mae: 1.8074 - mse: 6.2072 - val_loss: 17.2271 - val_mae: 2.6952 - val_mse: 17.2271\n",
      "Epoch 111/200\n",
      "26/26 - 0s - 5ms/step - loss: 6.2032 - mae: 1.7871 - mse: 6.2032 - val_loss: 18.2441 - val_mae: 2.7233 - val_mse: 18.2441\n",
      "Epoch 112/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.1534 - mae: 1.7900 - mse: 6.1534 - val_loss: 17.8415 - val_mae: 2.6962 - val_mse: 17.8415\n",
      "Epoch 113/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.0575 - mae: 1.7862 - mse: 6.0575 - val_loss: 18.1786 - val_mae: 2.7840 - val_mse: 18.1786\n",
      "Epoch 114/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.0003 - mae: 1.7534 - mse: 6.0003 - val_loss: 18.6238 - val_mae: 2.7834 - val_mse: 18.6238\n",
      "Epoch 115/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.1031 - mae: 1.7978 - mse: 6.1031 - val_loss: 17.2486 - val_mae: 2.6766 - val_mse: 17.2486\n",
      "Epoch 116/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.0854 - mae: 1.7835 - mse: 6.0854 - val_loss: 17.0354 - val_mae: 2.6594 - val_mse: 17.0354\n",
      "Epoch 117/200\n",
      "26/26 - 0s - 4ms/step - loss: 6.0435 - mae: 1.7819 - mse: 6.0435 - val_loss: 18.0709 - val_mae: 2.7384 - val_mse: 18.0709\n",
      "Epoch 118/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.9261 - mae: 1.7547 - mse: 5.9261 - val_loss: 17.3817 - val_mae: 2.6900 - val_mse: 17.3817\n",
      "Epoch 119/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.9177 - mae: 1.7508 - mse: 5.9177 - val_loss: 16.9505 - val_mae: 2.6569 - val_mse: 16.9505\n",
      "Epoch 120/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.9553 - mae: 1.7581 - mse: 5.9553 - val_loss: 17.8126 - val_mae: 2.7471 - val_mse: 17.8126\n",
      "Epoch 121/200\n",
      "26/26 - 0s - 5ms/step - loss: 5.8908 - mae: 1.7494 - mse: 5.8908 - val_loss: 17.6228 - val_mae: 2.6798 - val_mse: 17.6228\n",
      "Epoch 122/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.8735 - mae: 1.7433 - mse: 5.8735 - val_loss: 19.1083 - val_mae: 2.8993 - val_mse: 19.1083\n",
      "Epoch 123/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.8763 - mae: 1.7415 - mse: 5.8763 - val_loss: 18.4765 - val_mae: 2.7632 - val_mse: 18.4765\n",
      "Epoch 124/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.8652 - mae: 1.7600 - mse: 5.8652 - val_loss: 17.6984 - val_mae: 2.7740 - val_mse: 17.6984\n",
      "Epoch 125/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.8540 - mae: 1.7447 - mse: 5.8540 - val_loss: 17.3470 - val_mae: 2.7166 - val_mse: 17.3470\n",
      "Epoch 126/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.7576 - mae: 1.7301 - mse: 5.7576 - val_loss: 18.2852 - val_mae: 2.7589 - val_mse: 18.2852\n",
      "Epoch 127/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.7878 - mae: 1.7353 - mse: 5.7878 - val_loss: 16.4253 - val_mae: 2.6079 - val_mse: 16.4253\n",
      "Epoch 128/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.7958 - mae: 1.7490 - mse: 5.7958 - val_loss: 16.3329 - val_mae: 2.6161 - val_mse: 16.3329\n",
      "Epoch 129/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.7990 - mae: 1.7359 - mse: 5.7990 - val_loss: 17.7185 - val_mae: 2.7448 - val_mse: 17.7185\n",
      "Epoch 130/200\n",
      "26/26 - 0s - 5ms/step - loss: 5.7803 - mae: 1.7455 - mse: 5.7803 - val_loss: 17.8033 - val_mae: 2.7240 - val_mse: 17.8033\n",
      "Epoch 131/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.6796 - mae: 1.7155 - mse: 5.6796 - val_loss: 16.4051 - val_mae: 2.6097 - val_mse: 16.4051\n",
      "Epoch 132/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.6948 - mae: 1.7229 - mse: 5.6948 - val_loss: 16.3133 - val_mae: 2.5723 - val_mse: 16.3133\n",
      "Epoch 133/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.7537 - mae: 1.7398 - mse: 5.7537 - val_loss: 17.6950 - val_mae: 2.7579 - val_mse: 17.6950\n",
      "Epoch 134/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.5438 - mae: 1.7053 - mse: 5.5438 - val_loss: 17.7390 - val_mae: 2.7790 - val_mse: 17.7390\n",
      "Epoch 135/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.6006 - mae: 1.7080 - mse: 5.6006 - val_loss: 16.2439 - val_mae: 2.5795 - val_mse: 16.2439\n",
      "Epoch 136/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.6093 - mae: 1.7099 - mse: 5.6093 - val_loss: 17.3002 - val_mae: 2.7139 - val_mse: 17.3002\n",
      "Epoch 137/200\n",
      "26/26 - 0s - 5ms/step - loss: 5.5276 - mae: 1.6914 - mse: 5.5276 - val_loss: 16.7761 - val_mae: 2.6469 - val_mse: 16.7761\n",
      "Epoch 138/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.5174 - mae: 1.7026 - mse: 5.5174 - val_loss: 16.0103 - val_mae: 2.5625 - val_mse: 16.0103\n",
      "Epoch 139/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.6201 - mae: 1.7327 - mse: 5.6201 - val_loss: 17.8255 - val_mae: 2.7556 - val_mse: 17.8255\n",
      "Epoch 140/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.5548 - mae: 1.6991 - mse: 5.5548 - val_loss: 16.3518 - val_mae: 2.5822 - val_mse: 16.3518\n",
      "Epoch 141/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.6394 - mae: 1.7210 - mse: 5.6394 - val_loss: 16.4430 - val_mae: 2.5958 - val_mse: 16.4430\n",
      "Epoch 142/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.4778 - mae: 1.6890 - mse: 5.4778 - val_loss: 17.8264 - val_mae: 2.7390 - val_mse: 17.8264\n",
      "Epoch 143/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.5353 - mae: 1.7026 - mse: 5.5353 - val_loss: 16.6352 - val_mae: 2.6297 - val_mse: 16.6352\n",
      "Epoch 144/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.4440 - mae: 1.6840 - mse: 5.4440 - val_loss: 16.5613 - val_mae: 2.6599 - val_mse: 16.5613\n",
      "Epoch 145/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.4914 - mae: 1.7139 - mse: 5.4914 - val_loss: 15.7387 - val_mae: 2.5523 - val_mse: 15.7387\n",
      "Epoch 146/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.4405 - mae: 1.6836 - mse: 5.4405 - val_loss: 16.1210 - val_mae: 2.5843 - val_mse: 16.1210\n",
      "Epoch 147/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.3877 - mae: 1.6734 - mse: 5.3877 - val_loss: 16.8571 - val_mae: 2.6419 - val_mse: 16.8571\n",
      "Epoch 148/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.3833 - mae: 1.7016 - mse: 5.3833 - val_loss: 16.9544 - val_mae: 2.6857 - val_mse: 16.9544\n",
      "Epoch 149/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.3189 - mae: 1.6792 - mse: 5.3189 - val_loss: 16.5667 - val_mae: 2.6610 - val_mse: 16.5667\n",
      "Epoch 150/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.3528 - mae: 1.6765 - mse: 5.3528 - val_loss: 17.1050 - val_mae: 2.7144 - val_mse: 17.1050\n",
      "Epoch 151/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.3674 - mae: 1.6869 - mse: 5.3674 - val_loss: 16.6435 - val_mae: 2.6398 - val_mse: 16.6435\n",
      "Epoch 152/200\n",
      "26/26 - 0s - 5ms/step - loss: 5.3320 - mae: 1.6660 - mse: 5.3320 - val_loss: 16.8182 - val_mae: 2.6797 - val_mse: 16.8182\n",
      "Epoch 153/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.3463 - mae: 1.6771 - mse: 5.3463 - val_loss: 15.8389 - val_mae: 2.5700 - val_mse: 15.8389\n",
      "Epoch 154/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.2532 - mae: 1.6655 - mse: 5.2532 - val_loss: 15.5077 - val_mae: 2.6307 - val_mse: 15.5077\n",
      "Epoch 155/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.5097 - mae: 1.6870 - mse: 5.5097 - val_loss: 16.0383 - val_mae: 2.5839 - val_mse: 16.0383\n",
      "Epoch 156/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.2094 - mae: 1.6528 - mse: 5.2094 - val_loss: 16.0301 - val_mae: 2.5825 - val_mse: 16.0301\n",
      "Epoch 157/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.1967 - mae: 1.6613 - mse: 5.1967 - val_loss: 16.0666 - val_mae: 2.5916 - val_mse: 16.0666\n",
      "Epoch 158/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.2562 - mae: 1.6489 - mse: 5.2562 - val_loss: 15.4739 - val_mae: 2.5146 - val_mse: 15.4739\n",
      "Epoch 159/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.3034 - mae: 1.6656 - mse: 5.3034 - val_loss: 17.1490 - val_mae: 2.7265 - val_mse: 17.1490\n",
      "Epoch 160/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.0720 - mae: 1.6240 - mse: 5.0720 - val_loss: 16.5222 - val_mae: 2.5834 - val_mse: 16.5222\n",
      "Epoch 161/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.1808 - mae: 1.6649 - mse: 5.1808 - val_loss: 16.0795 - val_mae: 2.5896 - val_mse: 16.0795\n",
      "Epoch 162/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.1551 - mae: 1.6532 - mse: 5.1551 - val_loss: 16.1174 - val_mae: 2.6156 - val_mse: 16.1174\n",
      "Epoch 163/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.0899 - mae: 1.6302 - mse: 5.0899 - val_loss: 16.3053 - val_mae: 2.6252 - val_mse: 16.3053\n",
      "Epoch 164/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.1261 - mae: 1.6597 - mse: 5.1261 - val_loss: 16.0186 - val_mae: 2.6143 - val_mse: 16.0186\n",
      "Epoch 165/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.1130 - mae: 1.6465 - mse: 5.1130 - val_loss: 15.9976 - val_mae: 2.5449 - val_mse: 15.9976\n",
      "Epoch 166/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.2148 - mae: 1.6575 - mse: 5.2148 - val_loss: 15.5133 - val_mae: 2.5367 - val_mse: 15.5133\n",
      "Epoch 167/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.1013 - mae: 1.6512 - mse: 5.1013 - val_loss: 17.4334 - val_mae: 2.7518 - val_mse: 17.4334\n",
      "Epoch 168/200\n",
      "26/26 - 0s - 5ms/step - loss: 5.1919 - mae: 1.6681 - mse: 5.1919 - val_loss: 16.8575 - val_mae: 2.6834 - val_mse: 16.8575\n",
      "Epoch 169/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.0552 - mae: 1.6290 - mse: 5.0552 - val_loss: 16.1679 - val_mae: 2.5785 - val_mse: 16.1679\n",
      "Epoch 170/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.0962 - mae: 1.6354 - mse: 5.0962 - val_loss: 16.0615 - val_mae: 2.5827 - val_mse: 16.0615\n",
      "Epoch 171/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.9592 - mae: 1.6036 - mse: 4.9592 - val_loss: 16.3219 - val_mae: 2.5857 - val_mse: 16.3219\n",
      "Epoch 172/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.9917 - mae: 1.6339 - mse: 4.9917 - val_loss: 14.6651 - val_mae: 2.4630 - val_mse: 14.6651\n",
      "Epoch 173/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.0594 - mae: 1.6344 - mse: 5.0594 - val_loss: 15.6737 - val_mae: 2.5493 - val_mse: 15.6737\n",
      "Epoch 174/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.9528 - mae: 1.6210 - mse: 4.9528 - val_loss: 15.3779 - val_mae: 2.5067 - val_mse: 15.3779\n",
      "Epoch 175/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.0390 - mae: 1.6162 - mse: 5.0390 - val_loss: 15.4819 - val_mae: 2.5198 - val_mse: 15.4819\n",
      "Epoch 176/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.0128 - mae: 1.6287 - mse: 5.0128 - val_loss: 17.1969 - val_mae: 2.7777 - val_mse: 17.1969\n",
      "Epoch 177/200\n",
      "26/26 - 0s - 4ms/step - loss: 5.0234 - mae: 1.6353 - mse: 5.0234 - val_loss: 15.5832 - val_mae: 2.5550 - val_mse: 15.5832\n",
      "Epoch 178/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.8447 - mae: 1.5951 - mse: 4.8447 - val_loss: 15.7011 - val_mae: 2.5432 - val_mse: 15.7011\n",
      "Epoch 179/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.9196 - mae: 1.5967 - mse: 4.9196 - val_loss: 15.5409 - val_mae: 2.5582 - val_mse: 15.5409\n",
      "Epoch 180/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.9757 - mae: 1.6078 - mse: 4.9757 - val_loss: 16.1649 - val_mae: 2.6215 - val_mse: 16.1649\n",
      "Epoch 181/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.8716 - mae: 1.6053 - mse: 4.8716 - val_loss: 16.4968 - val_mae: 2.6557 - val_mse: 16.4968\n",
      "Epoch 182/200\n",
      "26/26 - 0s - 5ms/step - loss: 4.8748 - mae: 1.6147 - mse: 4.8748 - val_loss: 15.8134 - val_mae: 2.5307 - val_mse: 15.8134\n",
      "Epoch 183/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.8021 - mae: 1.6084 - mse: 4.8021 - val_loss: 16.1476 - val_mae: 2.6397 - val_mse: 16.1476\n",
      "Epoch 184/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.9518 - mae: 1.6218 - mse: 4.9518 - val_loss: 16.1311 - val_mae: 2.6210 - val_mse: 16.1311\n",
      "Epoch 185/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.7996 - mae: 1.5769 - mse: 4.7996 - val_loss: 16.3512 - val_mae: 2.6102 - val_mse: 16.3512\n",
      "Epoch 186/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.7765 - mae: 1.6051 - mse: 4.7765 - val_loss: 15.4939 - val_mae: 2.5116 - val_mse: 15.4939\n",
      "Epoch 187/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.8496 - mae: 1.5864 - mse: 4.8496 - val_loss: 19.3777 - val_mae: 2.9312 - val_mse: 19.3777\n",
      "Epoch 188/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.8816 - mae: 1.6196 - mse: 4.8816 - val_loss: 15.8279 - val_mae: 2.5666 - val_mse: 15.8279\n",
      "Epoch 189/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.8008 - mae: 1.6259 - mse: 4.8008 - val_loss: 15.8040 - val_mae: 2.5644 - val_mse: 15.8040\n",
      "Epoch 190/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.8030 - mae: 1.6034 - mse: 4.8030 - val_loss: 15.1545 - val_mae: 2.4977 - val_mse: 15.1545\n",
      "Epoch 191/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.7656 - mae: 1.5995 - mse: 4.7656 - val_loss: 15.5331 - val_mae: 2.5573 - val_mse: 15.5331\n",
      "Epoch 192/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.7602 - mae: 1.5829 - mse: 4.7602 - val_loss: 15.3848 - val_mae: 2.5287 - val_mse: 15.3848\n",
      "Epoch 193/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.6771 - mae: 1.5649 - mse: 4.6771 - val_loss: 16.0420 - val_mae: 2.6007 - val_mse: 16.0420\n",
      "Epoch 194/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.7871 - mae: 1.6080 - mse: 4.7871 - val_loss: 15.7678 - val_mae: 2.5520 - val_mse: 15.7678\n",
      "Epoch 195/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.7565 - mae: 1.5835 - mse: 4.7565 - val_loss: 15.4253 - val_mae: 2.5396 - val_mse: 15.4253\n",
      "Epoch 196/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.6894 - mae: 1.5935 - mse: 4.6894 - val_loss: 14.9452 - val_mae: 2.4687 - val_mse: 14.9452\n",
      "Epoch 197/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.7102 - mae: 1.5824 - mse: 4.7102 - val_loss: 15.1597 - val_mae: 2.4796 - val_mse: 15.1597\n",
      "Epoch 198/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.6640 - mae: 1.5877 - mse: 4.6640 - val_loss: 15.1326 - val_mae: 2.4949 - val_mse: 15.1326\n",
      "Epoch 199/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.6904 - mae: 1.5654 - mse: 4.6904 - val_loss: 15.0278 - val_mae: 2.4838 - val_mse: 15.0278\n",
      "Epoch 200/200\n",
      "26/26 - 0s - 4ms/step - loss: 4.7057 - mae: 1.5927 - mse: 4.7057 - val_loss: 15.4149 - val_mae: 2.5313 - val_mse: 15.4149\n",
      "4/4 - 0s - 27ms/step - loss: 15.4149 - mae: 2.5313 - mse: 15.4149\n",
      "Test loss (MSE): 15.4149\n",
      "Test MAE: 2.5313\n",
      "Test MSE: 15.4149\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(x_train.shape[1],)),\n",
    "    layers.Dense(32, activation=\"sigmoid\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=\"SGD\",\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "eval_results = model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss (MSE): {eval_results[0]:.4f}\")\n",
    "print(f\"Test MAE: {eval_results[1]:.4f}\")\n",
    "print(f\"Test MSE: {eval_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

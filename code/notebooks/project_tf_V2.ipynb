{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e6ff7d-cf32-4ac3-a5d6-ac81c8d0fa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 10:29:23.541914: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745911763.629829    7176 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745911763.653855    7176 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-29 10:29:23.808496: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21366e2b-aeba-4d49-a799-b3314a3e4c61",
   "metadata": {},
   "source": [
    "# loading data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b10e9fb-5b03-4882-b7be-9ab15c0ed301",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images train before normalize and processing (60000, 28, 28)\n",
      "images train after reshaping (60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745833014.153039   12211 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1225 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-04-28 12:36:54.154724: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 47040000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 784\n",
    "HIDDEN_SIZE = 32\n",
    "OUTPUT_SIZE = 10\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "(x_train,y_train),(x_test, y_test) = mnist.load_data()\n",
    "print(\"images train before normalize and processing\",x_train.shape)\n",
    "\n",
    "x_train = tf.reshape(x_train, [-1, 28*28])\n",
    "x_test = tf.reshape(x_test, [-1, 28*28])\n",
    "\n",
    "print(\"images train after reshaping\",x_train.shape)\n",
    "# x_train[1]\n",
    "\n",
    "# handling pixels to be only black and white from gray scale\n",
    "x_train = tf.cast(x_train, tf.float32) / 255.0\n",
    "x_test = tf.cast(x_test, tf.float32) / 255.0\n",
    "\n",
    "\n",
    "y_train_hot = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_hot = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "print(y_train_hot.shape)\n",
    "print(y_test_hot.shape)\n",
    "\n",
    "y_train_hot = tf.convert_to_tensor(y_train_hot, dtype=tf.float32)\n",
    "y_test_hot = tf.convert_to_tensor(y_test_hot, dtype=tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571986e8-327a-4156-8c72-5337733790f6",
   "metadata": {},
   "source": [
    "# neural netowrk structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec15469-18ff-4097-bffe-0e8c36b2e356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac4c9f2-a658-4d18-b224-6ae365ab20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 784\n",
    "HIDDEN_SIZE = 32\n",
    "OUTPUT_SIZE = 10\n",
    "\n",
    "def sigmoid(x):\n",
    "    return tf.nn.sigmoid(x)\n",
    "\n",
    "def softmax(x):\n",
    "    return tf.nn.softmax(x)\n",
    "\n",
    "w1_size = INPUT_SIZE * HIDDEN_SIZE\n",
    "b1_size = HIDDEN_SIZE\n",
    "w2_size = HIDDEN_SIZE * OUTPUT_SIZE\n",
    "b2_size = OUTPUT_SIZE\n",
    "D = w1_size + b1_size + w2_size + b2_size\n",
    "\n",
    "\n",
    "def decode_weights(vector):\n",
    "    \n",
    "    w1_size = INPUT_SIZE * HIDDEN_SIZE\n",
    "    b1_size = HIDDEN_SIZE\n",
    "    w2_size = HIDDEN_SIZE * OUTPUT_SIZE\n",
    "    b2_size = OUTPUT_SIZE\n",
    "    \n",
    "    idx = 0\n",
    "    w1 = tf.reshape(vector[idx:idx + w1_size], [INPUT_SIZE, HIDDEN_SIZE])\n",
    "    idx += w1_size\n",
    "    \n",
    "    b1 = vector[idx:idx + b1_size]\n",
    "    idx += b1_size\n",
    "    \n",
    "    w2 = tf.reshape(vector[idx:idx + w2_size], [HIDDEN_SIZE, OUTPUT_SIZE])\n",
    "    idx += w2_size\n",
    "    \n",
    "    b2 = vector[idx:idx + b2_size]\n",
    "    \n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "\n",
    "def forward_pass(X, vector):\n",
    "    w1, b1, w2, b2 = decode_weights(vector)\n",
    "    \n",
    "    hidden = sigmoid(tf.matmul(X, w1) + b1)\n",
    "    output = softmax(tf.matmul(hidden, w2) + b2)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def fitness(vector, X, y_true, batch_size=1000):\n",
    "    \n",
    "    indices = np.random.choice(X.shape[0], batch_size, replace=False)\n",
    "    X_batch = tf.gather(X, indices)\n",
    "    y_batch = tf.gather(y_true, indices)\n",
    "    \n",
    "    y_pred = forward_pass(X_batch, vector)\n",
    "    loss = tf.keras.losses.categorical_crossentropy(y_batch, y_pred)\n",
    "    return tf.reduce_mean(loss)\n",
    "    \n",
    "# def fitness(vector, X, y_true):\n",
    "#     y_pred = forward_pass(X, vector)\n",
    "    \n",
    "#     loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    \n",
    "#     return tf.reduce_mean(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b994a81c-fce3-47ee-9c75-f05198ffff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 2.3015012741088867\n"
     ]
    }
   ],
   "source": [
    "total_weights = INPUT_SIZE * HIDDEN_SIZE + HIDDEN_SIZE + HIDDEN_SIZE * OUTPUT_SIZE + OUTPUT_SIZE\n",
    "vector_np = np.random.randn(total_weights) * 0.01\n",
    "vector_tf = tf.convert_to_tensor(vector_np, dtype=tf.float32)\n",
    "\n",
    "loss = fitness(vector_tf, x_train, y_train_hot)\n",
    "print(f\"Initial loss: {loss.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3666874b-ec79-4d7b-a0bf-a440b077524b",
   "metadata": {},
   "source": [
    "# functions for the DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf65eb9-246b-4f92-8257-d851c66485b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def initialize_population(population_size, D, input_dim=784, output_dim=10):\n",
    "    \n",
    "    xavier_scaling = tf.sqrt(6.0 / tf.cast(input_dim + output_dim, tf.float32))\n",
    "    population = tf.random.uniform(\n",
    "        shape=(population_size, D),\n",
    "        minval=-xavier_scaling,\n",
    "        maxval=xavier_scaling,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    \n",
    "    return population\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "061bb2db-b92e-4c15-bc04-73bf320dd4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_vectors(population, current_idx):\n",
    "    indices = tf.range(NP)\n",
    "    mask = indices != current_idx\n",
    "    valid_indices = tf.boolean_mask(indices, mask)\n",
    "    selected_indices = tf.random.shuffle(valid_indices)[:3]\n",
    "    return [population[idx] for idx in selected_indices]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3adc243-6b8a-4d6b-9fb5-204f893c42b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(x1, x2, x3, F, D, L=-1, H=1):\n",
    "\n",
    "    v = x3 + F * (x1 - x2)\n",
    "    \n",
    "    out_of_bounds = tf.logical_or(v < L, v > H) # returns tensor fo booleans where true is erorr\n",
    "    \n",
    "    random_values = L + tf.random.uniform(shape=(D,), dtype=tf.float32) * (H - L)\n",
    "    \n",
    "    v = tf.where(out_of_bounds, random_values, v) # checks where true and takes value from the random value if false takes from v\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5b25a-12cb-41fe-a0d3-b913aab48b3c",
   "metadata": {},
   "source": [
    " <p>example of how we did the mutate and how mask works</p>\n",
    "<img src=\"Screenshot_20250424_015153.png\" alt=\"Project Screenshot\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ddbd642-d61c-43b1-8698-c203c45b2309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(target_vector, mutant_vector, CR, D):\n",
    "\n",
    "    # instead of loop and check we make the whole vecotor once and check with mask\n",
    "    r = tf.random.uniform(shape=(D,), dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    mask = r < CR  # mask is tensor flow boolean vecotr\n",
    "    \n",
    "    trial_vector = tf.where(mask, mutant_vector, target_vector)\n",
    "    \n",
    "    return trial_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c103ff3-dfed-41ed-ac93-7db3f5e23094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "532c4daf-841a-4da9-b657-d87912202471",
   "metadata": {},
   "source": [
    "# main evolve function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97352aa1-cb47-4930-a18d-8a4404846b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evolve(population, GEN, NP, D, F, CR, x_train, y_train, fitness_func, L=-0.5, H=0.5):\n",
    "\n",
    "    # best solution\n",
    "    fitness_scores = [fitness_func(ind, x_train, y_train) for ind in population]\n",
    "    best_idx = tf.argmin(fitness_scores)\n",
    "    best_solution = tf.identity(population[best_idx])  # tf.identity is copy to set it as the best solution \n",
    "    best_fitness = fitness_scores[best_idx]\n",
    "    \n",
    "    fitness_history = []\n",
    "\n",
    "    for g in range(GEN):\n",
    "                \n",
    "        new_population = [tf.identity(ind) for ind in population] #copy of the population for this generation\n",
    "\n",
    "        new_fitness_scores = list(fitness_scores) \n",
    "        \n",
    "        for j in range(NP):\n",
    "            \n",
    "            v1, v2, v3 = random_vectors(population, j)\n",
    "            mutant_vector = mutate(v1, v2, v3, F, D, L, H)\n",
    "            \n",
    "            target_vector = tf.identity(population[j])         \n",
    "            trial_vector = crossover(target_vector, mutant_vector, CR, D)\n",
    "            \n",
    "            trial_fitness = fitness_func(trial_vector, x_train, y_train)\n",
    "            target_fitness = new_fitness_scores[j]\n",
    "            \n",
    "            if trial_fitness < target_fitness:\n",
    "                new_population[j] = trial_vector\n",
    "                new_fitness_scores[j] = trial_fitness\n",
    "                    \n",
    "                \n",
    "                if trial_fitness < best_fitness:\n",
    "                    best_solution = tf.identity(trial_vector)\n",
    "                    best_fitness = trial_fitness\n",
    "\n",
    "        \n",
    "        \n",
    "        # each genration swap worst for our best soultion   and send it to next population \n",
    "        worst_idx = tf.argmax(new_fitness_scores).numpy()  #get highest fitness / worst indfivsual \n",
    "        \n",
    "        if new_fitness_scores[worst_idx] > best_fitness:\n",
    "            new_population[worst_idx] = tf.identity(best_solution)\n",
    "            new_fitness_scores[worst_idx] = best_fitness\n",
    "            \n",
    "            \n",
    "        # upate population with new poulation for next genration \n",
    "        for i in range(NP):\n",
    "            population[i].assign(new_population[i])\n",
    "        fitness_scores = new_fitness_scores\n",
    "        \n",
    "        fitness_history.append(best_fitness)\n",
    "        \n",
    "        print(f\"Generation {g+1}/{GEN}: Best fitness (loss) = {best_fitness:.6f}\")\n",
    "    \n",
    "    return best_solution ,fitness_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce021220-f90f-4eb5-a873-77b8895930ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population shape is :  (50, 25450)\n",
      "Generation 1/700: Best fitness (loss) = 2.294157\n",
      "Generation 2/700: Best fitness (loss) = 2.294157\n",
      "Generation 3/700: Best fitness (loss) = 2.294157\n",
      "Generation 4/700: Best fitness (loss) = 2.294157\n",
      "Generation 5/700: Best fitness (loss) = 2.287879\n",
      "Generation 6/700: Best fitness (loss) = 2.279685\n",
      "Generation 7/700: Best fitness (loss) = 2.276908\n",
      "Generation 8/700: Best fitness (loss) = 2.273765\n",
      "Generation 9/700: Best fitness (loss) = 2.273765\n",
      "Generation 10/700: Best fitness (loss) = 2.255981\n",
      "Generation 11/700: Best fitness (loss) = 2.227511\n",
      "Generation 12/700: Best fitness (loss) = 2.227511\n",
      "Generation 13/700: Best fitness (loss) = 2.227511\n",
      "Generation 14/700: Best fitness (loss) = 2.200357\n",
      "Generation 15/700: Best fitness (loss) = 2.200357\n",
      "Generation 16/700: Best fitness (loss) = 2.168295\n",
      "Generation 17/700: Best fitness (loss) = 2.168295\n",
      "Generation 18/700: Best fitness (loss) = 2.168295\n",
      "Generation 19/700: Best fitness (loss) = 2.168295\n",
      "Generation 20/700: Best fitness (loss) = 2.168295\n",
      "Generation 21/700: Best fitness (loss) = 2.168295\n",
      "Generation 22/700: Best fitness (loss) = 2.153277\n",
      "Generation 23/700: Best fitness (loss) = 2.138005\n",
      "Generation 24/700: Best fitness (loss) = 2.138005\n",
      "Generation 25/700: Best fitness (loss) = 2.138005\n",
      "Generation 26/700: Best fitness (loss) = 2.138005\n",
      "Generation 27/700: Best fitness (loss) = 2.138005\n",
      "Generation 28/700: Best fitness (loss) = 2.138005\n",
      "Generation 29/700: Best fitness (loss) = 2.138005\n",
      "Generation 30/700: Best fitness (loss) = 2.138005\n",
      "Generation 31/700: Best fitness (loss) = 2.138005\n",
      "Generation 32/700: Best fitness (loss) = 2.138005\n",
      "Generation 33/700: Best fitness (loss) = 2.138005\n",
      "Generation 34/700: Best fitness (loss) = 2.138005\n",
      "Generation 35/700: Best fitness (loss) = 2.123994\n",
      "Generation 36/700: Best fitness (loss) = 2.119068\n",
      "Generation 37/700: Best fitness (loss) = 2.119068\n",
      "Generation 38/700: Best fitness (loss) = 2.119068\n",
      "Generation 39/700: Best fitness (loss) = 2.119068\n",
      "Generation 40/700: Best fitness (loss) = 2.119068\n",
      "Generation 41/700: Best fitness (loss) = 2.119068\n",
      "Generation 42/700: Best fitness (loss) = 2.092011\n",
      "Generation 43/700: Best fitness (loss) = 2.086924\n",
      "Generation 44/700: Best fitness (loss) = 2.076797\n",
      "Generation 45/700: Best fitness (loss) = 2.076797\n",
      "Generation 46/700: Best fitness (loss) = 2.076797\n",
      "Generation 47/700: Best fitness (loss) = 2.069865\n",
      "Generation 48/700: Best fitness (loss) = 2.069865\n",
      "Generation 49/700: Best fitness (loss) = 2.056839\n",
      "Generation 50/700: Best fitness (loss) = 2.043424\n",
      "Generation 51/700: Best fitness (loss) = 2.028533\n",
      "Generation 52/700: Best fitness (loss) = 2.028533\n",
      "Generation 53/700: Best fitness (loss) = 2.028533\n",
      "Generation 54/700: Best fitness (loss) = 2.028533\n",
      "Generation 55/700: Best fitness (loss) = 2.028533\n",
      "Generation 56/700: Best fitness (loss) = 2.028533\n",
      "Generation 57/700: Best fitness (loss) = 2.028533\n",
      "Generation 58/700: Best fitness (loss) = 2.028533\n",
      "Generation 59/700: Best fitness (loss) = 2.024117\n",
      "Generation 60/700: Best fitness (loss) = 2.024117\n",
      "Generation 61/700: Best fitness (loss) = 1.998229\n",
      "Generation 62/700: Best fitness (loss) = 1.998229\n",
      "Generation 63/700: Best fitness (loss) = 1.998229\n",
      "Generation 64/700: Best fitness (loss) = 1.998229\n",
      "Generation 65/700: Best fitness (loss) = 1.998229\n",
      "Generation 66/700: Best fitness (loss) = 1.982375\n",
      "Generation 67/700: Best fitness (loss) = 1.982375\n",
      "Generation 68/700: Best fitness (loss) = 1.982375\n",
      "Generation 69/700: Best fitness (loss) = 1.982375\n",
      "Generation 70/700: Best fitness (loss) = 1.982375\n",
      "Generation 71/700: Best fitness (loss) = 1.973123\n",
      "Generation 72/700: Best fitness (loss) = 1.973123\n",
      "Generation 73/700: Best fitness (loss) = 1.965971\n",
      "Generation 74/700: Best fitness (loss) = 1.965971\n",
      "Generation 75/700: Best fitness (loss) = 1.965971\n",
      "Generation 76/700: Best fitness (loss) = 1.965971\n",
      "Generation 77/700: Best fitness (loss) = 1.960264\n",
      "Generation 78/700: Best fitness (loss) = 1.960264\n",
      "Generation 79/700: Best fitness (loss) = 1.942391\n",
      "Generation 80/700: Best fitness (loss) = 1.942391\n",
      "Generation 81/700: Best fitness (loss) = 1.942391\n",
      "Generation 82/700: Best fitness (loss) = 1.942391\n",
      "Generation 83/700: Best fitness (loss) = 1.920383\n",
      "Generation 84/700: Best fitness (loss) = 1.920383\n",
      "Generation 85/700: Best fitness (loss) = 1.920383\n",
      "Generation 86/700: Best fitness (loss) = 1.920383\n",
      "Generation 87/700: Best fitness (loss) = 1.920383\n",
      "Generation 88/700: Best fitness (loss) = 1.920383\n",
      "Generation 89/700: Best fitness (loss) = 1.920383\n",
      "Generation 90/700: Best fitness (loss) = 1.920383\n",
      "Generation 91/700: Best fitness (loss) = 1.920383\n",
      "Generation 92/700: Best fitness (loss) = 1.920383\n",
      "Generation 93/700: Best fitness (loss) = 1.920383\n",
      "Generation 94/700: Best fitness (loss) = 1.920383\n",
      "Generation 95/700: Best fitness (loss) = 1.920383\n",
      "Generation 96/700: Best fitness (loss) = 1.895020\n",
      "Generation 97/700: Best fitness (loss) = 1.895020\n",
      "Generation 98/700: Best fitness (loss) = 1.895020\n",
      "Generation 99/700: Best fitness (loss) = 1.895020\n",
      "Generation 100/700: Best fitness (loss) = 1.895020\n",
      "Generation 101/700: Best fitness (loss) = 1.878406\n",
      "Generation 102/700: Best fitness (loss) = 1.874255\n",
      "Generation 103/700: Best fitness (loss) = 1.874255\n",
      "Generation 104/700: Best fitness (loss) = 1.874255\n",
      "Generation 105/700: Best fitness (loss) = 1.874255\n",
      "Generation 106/700: Best fitness (loss) = 1.874255\n",
      "Generation 107/700: Best fitness (loss) = 1.874255\n",
      "Generation 108/700: Best fitness (loss) = 1.863877\n",
      "Generation 109/700: Best fitness (loss) = 1.863877\n",
      "Generation 110/700: Best fitness (loss) = 1.863877\n",
      "Generation 111/700: Best fitness (loss) = 1.863877\n",
      "Generation 112/700: Best fitness (loss) = 1.863877\n",
      "Generation 113/700: Best fitness (loss) = 1.863877\n",
      "Generation 114/700: Best fitness (loss) = 1.863877\n",
      "Generation 115/700: Best fitness (loss) = 1.863877\n",
      "Generation 116/700: Best fitness (loss) = 1.863877\n",
      "Generation 117/700: Best fitness (loss) = 1.826038\n",
      "Generation 118/700: Best fitness (loss) = 1.826038\n",
      "Generation 119/700: Best fitness (loss) = 1.826038\n",
      "Generation 120/700: Best fitness (loss) = 1.826038\n",
      "Generation 121/700: Best fitness (loss) = 1.826038\n",
      "Generation 122/700: Best fitness (loss) = 1.826038\n",
      "Generation 123/700: Best fitness (loss) = 1.826038\n",
      "Generation 124/700: Best fitness (loss) = 1.818781\n",
      "Generation 125/700: Best fitness (loss) = 1.808098\n",
      "Generation 126/700: Best fitness (loss) = 1.808098\n",
      "Generation 127/700: Best fitness (loss) = 1.808098\n",
      "Generation 128/700: Best fitness (loss) = 1.789981\n",
      "Generation 129/700: Best fitness (loss) = 1.789981\n",
      "Generation 130/700: Best fitness (loss) = 1.789981\n",
      "Generation 131/700: Best fitness (loss) = 1.789981\n",
      "Generation 132/700: Best fitness (loss) = 1.789981\n",
      "Generation 133/700: Best fitness (loss) = 1.789981\n",
      "Generation 134/700: Best fitness (loss) = 1.789981\n",
      "Generation 135/700: Best fitness (loss) = 1.789981\n",
      "Generation 136/700: Best fitness (loss) = 1.789981\n",
      "Generation 137/700: Best fitness (loss) = 1.789981\n",
      "Generation 138/700: Best fitness (loss) = 1.789981\n",
      "Generation 139/700: Best fitness (loss) = 1.789981\n",
      "Generation 140/700: Best fitness (loss) = 1.789981\n",
      "Generation 141/700: Best fitness (loss) = 1.789981\n",
      "Generation 142/700: Best fitness (loss) = 1.789981\n",
      "Generation 143/700: Best fitness (loss) = 1.789981\n",
      "Generation 144/700: Best fitness (loss) = 1.789981\n",
      "Generation 145/700: Best fitness (loss) = 1.789981\n",
      "Generation 146/700: Best fitness (loss) = 1.788651\n",
      "Generation 147/700: Best fitness (loss) = 1.788651\n",
      "Generation 148/700: Best fitness (loss) = 1.788651\n",
      "Generation 149/700: Best fitness (loss) = 1.788651\n",
      "Generation 150/700: Best fitness (loss) = 1.770588\n",
      "Generation 151/700: Best fitness (loss) = 1.770588\n",
      "Generation 152/700: Best fitness (loss) = 1.770588\n",
      "Generation 153/700: Best fitness (loss) = 1.770588\n",
      "Generation 154/700: Best fitness (loss) = 1.770588\n",
      "Generation 155/700: Best fitness (loss) = 1.770588\n",
      "Generation 156/700: Best fitness (loss) = 1.770588\n",
      "Generation 157/700: Best fitness (loss) = 1.770588\n",
      "Generation 158/700: Best fitness (loss) = 1.770588\n",
      "Generation 159/700: Best fitness (loss) = 1.764055\n",
      "Generation 160/700: Best fitness (loss) = 1.764055\n",
      "Generation 161/700: Best fitness (loss) = 1.752221\n",
      "Generation 162/700: Best fitness (loss) = 1.752221\n",
      "Generation 163/700: Best fitness (loss) = 1.752221\n",
      "Generation 164/700: Best fitness (loss) = 1.743863\n",
      "Generation 165/700: Best fitness (loss) = 1.743863\n",
      "Generation 166/700: Best fitness (loss) = 1.743863\n",
      "Generation 167/700: Best fitness (loss) = 1.729144\n",
      "Generation 168/700: Best fitness (loss) = 1.729144\n",
      "Generation 169/700: Best fitness (loss) = 1.729144\n",
      "Generation 170/700: Best fitness (loss) = 1.729144\n",
      "Generation 171/700: Best fitness (loss) = 1.729144\n",
      "Generation 172/700: Best fitness (loss) = 1.729144\n",
      "Generation 173/700: Best fitness (loss) = 1.729144\n",
      "Generation 174/700: Best fitness (loss) = 1.702116\n",
      "Generation 175/700: Best fitness (loss) = 1.702116\n",
      "Generation 176/700: Best fitness (loss) = 1.702116\n",
      "Generation 177/700: Best fitness (loss) = 1.702116\n",
      "Generation 178/700: Best fitness (loss) = 1.702116\n",
      "Generation 179/700: Best fitness (loss) = 1.702116\n",
      "Generation 180/700: Best fitness (loss) = 1.702116\n",
      "Generation 181/700: Best fitness (loss) = 1.702116\n",
      "Generation 182/700: Best fitness (loss) = 1.702116\n",
      "Generation 183/700: Best fitness (loss) = 1.702116\n",
      "Generation 184/700: Best fitness (loss) = 1.702116\n",
      "Generation 185/700: Best fitness (loss) = 1.702116\n",
      "Generation 186/700: Best fitness (loss) = 1.702116\n",
      "Generation 187/700: Best fitness (loss) = 1.702116\n",
      "Generation 188/700: Best fitness (loss) = 1.702116\n",
      "Generation 189/700: Best fitness (loss) = 1.702116\n",
      "Generation 190/700: Best fitness (loss) = 1.702116\n",
      "Generation 191/700: Best fitness (loss) = 1.702116\n",
      "Generation 192/700: Best fitness (loss) = 1.679433\n",
      "Generation 193/700: Best fitness (loss) = 1.679433\n",
      "Generation 194/700: Best fitness (loss) = 1.679433\n",
      "Generation 195/700: Best fitness (loss) = 1.679433\n",
      "Generation 196/700: Best fitness (loss) = 1.679433\n",
      "Generation 197/700: Best fitness (loss) = 1.679433\n",
      "Generation 198/700: Best fitness (loss) = 1.679433\n",
      "Generation 199/700: Best fitness (loss) = 1.679433\n",
      "Generation 200/700: Best fitness (loss) = 1.679433\n",
      "Generation 201/700: Best fitness (loss) = 1.679433\n",
      "Generation 202/700: Best fitness (loss) = 1.679433\n",
      "Generation 203/700: Best fitness (loss) = 1.679433\n",
      "Generation 204/700: Best fitness (loss) = 1.679433\n",
      "Generation 205/700: Best fitness (loss) = 1.679433\n",
      "Generation 206/700: Best fitness (loss) = 1.679433\n",
      "Generation 207/700: Best fitness (loss) = 1.679433\n",
      "Generation 208/700: Best fitness (loss) = 1.674754\n",
      "Generation 209/700: Best fitness (loss) = 1.674754\n",
      "Generation 210/700: Best fitness (loss) = 1.674754\n",
      "Generation 211/700: Best fitness (loss) = 1.674754\n",
      "Generation 212/700: Best fitness (loss) = 1.674754\n",
      "Generation 213/700: Best fitness (loss) = 1.674754\n",
      "Generation 214/700: Best fitness (loss) = 1.674754\n",
      "Generation 215/700: Best fitness (loss) = 1.662212\n",
      "Generation 216/700: Best fitness (loss) = 1.662212\n",
      "Generation 217/700: Best fitness (loss) = 1.662212\n",
      "Generation 218/700: Best fitness (loss) = 1.662212\n",
      "Generation 219/700: Best fitness (loss) = 1.662212\n",
      "Generation 220/700: Best fitness (loss) = 1.662212\n",
      "Generation 221/700: Best fitness (loss) = 1.662212\n",
      "Generation 222/700: Best fitness (loss) = 1.662212\n",
      "Generation 223/700: Best fitness (loss) = 1.662212\n",
      "Generation 224/700: Best fitness (loss) = 1.662212\n",
      "Generation 225/700: Best fitness (loss) = 1.662212\n",
      "Generation 226/700: Best fitness (loss) = 1.662212\n",
      "Generation 227/700: Best fitness (loss) = 1.662212\n",
      "Generation 228/700: Best fitness (loss) = 1.662212\n",
      "Generation 229/700: Best fitness (loss) = 1.662212\n",
      "Generation 230/700: Best fitness (loss) = 1.662212\n",
      "Generation 231/700: Best fitness (loss) = 1.662212\n",
      "Generation 232/700: Best fitness (loss) = 1.662212\n",
      "Generation 233/700: Best fitness (loss) = 1.662212\n",
      "Generation 234/700: Best fitness (loss) = 1.662212\n",
      "Generation 235/700: Best fitness (loss) = 1.662212\n",
      "Generation 236/700: Best fitness (loss) = 1.662212\n",
      "Generation 237/700: Best fitness (loss) = 1.662212\n",
      "Generation 238/700: Best fitness (loss) = 1.662212\n",
      "Generation 239/700: Best fitness (loss) = 1.662212\n",
      "Generation 240/700: Best fitness (loss) = 1.662212\n",
      "Generation 241/700: Best fitness (loss) = 1.660508\n",
      "Generation 242/700: Best fitness (loss) = 1.660508\n",
      "Generation 243/700: Best fitness (loss) = 1.657600\n",
      "Generation 244/700: Best fitness (loss) = 1.657600\n",
      "Generation 245/700: Best fitness (loss) = 1.657600\n",
      "Generation 246/700: Best fitness (loss) = 1.657600\n",
      "Generation 247/700: Best fitness (loss) = 1.657600\n",
      "Generation 248/700: Best fitness (loss) = 1.657600\n",
      "Generation 249/700: Best fitness (loss) = 1.657600\n",
      "Generation 250/700: Best fitness (loss) = 1.654233\n",
      "Generation 251/700: Best fitness (loss) = 1.654233\n",
      "Generation 252/700: Best fitness (loss) = 1.654233\n",
      "Generation 253/700: Best fitness (loss) = 1.654233\n",
      "Generation 254/700: Best fitness (loss) = 1.654233\n",
      "Generation 255/700: Best fitness (loss) = 1.654233\n",
      "Generation 256/700: Best fitness (loss) = 1.654233\n",
      "Generation 257/700: Best fitness (loss) = 1.654233\n",
      "Generation 258/700: Best fitness (loss) = 1.654233\n",
      "Generation 259/700: Best fitness (loss) = 1.654233\n",
      "Generation 260/700: Best fitness (loss) = 1.654233\n",
      "Generation 261/700: Best fitness (loss) = 1.654233\n",
      "Generation 262/700: Best fitness (loss) = 1.654233\n",
      "Generation 263/700: Best fitness (loss) = 1.654233\n",
      "Generation 264/700: Best fitness (loss) = 1.654233\n",
      "Generation 265/700: Best fitness (loss) = 1.654233\n",
      "Generation 266/700: Best fitness (loss) = 1.630743\n",
      "Generation 267/700: Best fitness (loss) = 1.630743\n",
      "Generation 268/700: Best fitness (loss) = 1.630743\n",
      "Generation 269/700: Best fitness (loss) = 1.630743\n",
      "Generation 270/700: Best fitness (loss) = 1.630743\n",
      "Generation 271/700: Best fitness (loss) = 1.630743\n",
      "Generation 272/700: Best fitness (loss) = 1.630743\n",
      "Generation 273/700: Best fitness (loss) = 1.630743\n",
      "Generation 274/700: Best fitness (loss) = 1.630743\n",
      "Generation 275/700: Best fitness (loss) = 1.630743\n",
      "Generation 276/700: Best fitness (loss) = 1.630743\n",
      "Generation 277/700: Best fitness (loss) = 1.630743\n",
      "Generation 278/700: Best fitness (loss) = 1.630743\n",
      "Generation 279/700: Best fitness (loss) = 1.630743\n",
      "Generation 280/700: Best fitness (loss) = 1.630743\n",
      "Generation 281/700: Best fitness (loss) = 1.630743\n",
      "Generation 282/700: Best fitness (loss) = 1.630743\n",
      "Generation 283/700: Best fitness (loss) = 1.630743\n",
      "Generation 284/700: Best fitness (loss) = 1.630743\n",
      "Generation 285/700: Best fitness (loss) = 1.630743\n",
      "Generation 286/700: Best fitness (loss) = 1.630743\n",
      "Generation 287/700: Best fitness (loss) = 1.630743\n",
      "Generation 288/700: Best fitness (loss) = 1.630743\n",
      "Generation 289/700: Best fitness (loss) = 1.630743\n",
      "Generation 290/700: Best fitness (loss) = 1.630743\n",
      "Generation 291/700: Best fitness (loss) = 1.630743\n",
      "Generation 292/700: Best fitness (loss) = 1.630743\n",
      "Generation 293/700: Best fitness (loss) = 1.630743\n",
      "Generation 294/700: Best fitness (loss) = 1.630743\n",
      "Generation 295/700: Best fitness (loss) = 1.630743\n",
      "Generation 296/700: Best fitness (loss) = 1.630743\n",
      "Generation 297/700: Best fitness (loss) = 1.630743\n",
      "Generation 298/700: Best fitness (loss) = 1.630743\n",
      "Generation 299/700: Best fitness (loss) = 1.630743\n",
      "Generation 300/700: Best fitness (loss) = 1.630743\n",
      "Generation 301/700: Best fitness (loss) = 1.630743\n",
      "Generation 302/700: Best fitness (loss) = 1.630743\n",
      "Generation 303/700: Best fitness (loss) = 1.630743\n",
      "Generation 304/700: Best fitness (loss) = 1.630743\n",
      "Generation 305/700: Best fitness (loss) = 1.630743\n",
      "Generation 306/700: Best fitness (loss) = 1.630743\n",
      "Generation 307/700: Best fitness (loss) = 1.630743\n",
      "Generation 308/700: Best fitness (loss) = 1.630743\n",
      "Generation 309/700: Best fitness (loss) = 1.630743\n",
      "Generation 310/700: Best fitness (loss) = 1.630743\n",
      "Generation 311/700: Best fitness (loss) = 1.630743\n",
      "Generation 312/700: Best fitness (loss) = 1.630743\n",
      "Generation 313/700: Best fitness (loss) = 1.630743\n",
      "Generation 314/700: Best fitness (loss) = 1.630743\n",
      "Generation 315/700: Best fitness (loss) = 1.630743\n",
      "Generation 316/700: Best fitness (loss) = 1.630743\n",
      "Generation 317/700: Best fitness (loss) = 1.630743\n",
      "Generation 318/700: Best fitness (loss) = 1.630743\n",
      "Generation 319/700: Best fitness (loss) = 1.630743\n",
      "Generation 320/700: Best fitness (loss) = 1.630743\n",
      "Generation 321/700: Best fitness (loss) = 1.630743\n"
     ]
    }
   ],
   "source": [
    "NP = 50\n",
    "GEN=700\n",
    "seed = 24\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "population = initialize_population(population_size=NP ,D=D)\n",
    "print(\"population shape is : \",population.shape)\n",
    "population = tf.Variable(population)\n",
    "result, history = evolve(population, GEN, NP, D, 0.8, 0.7, x_train, y_train_hot,fitness, L=-1, H=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d06e1a-283b-463b-9c2b-8fa9c70ffadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fitness_values = [float(tensor.numpy()) for tensor in history]\n",
    "generations = list(range(len(fitness_values)))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the fitness trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=generations,\n",
    "    y=fitness_values,\n",
    "    mode='lines',\n",
    "    name='Fitness (Loss)',\n",
    "    line=dict(color='blue', width=2)\n",
    "))\n",
    "\n",
    "\n",
    "significant_points = []\n",
    "if len(fitness_values) > 1:\n",
    "    prev_value = fitness_values[0]\n",
    "    for i, value in enumerate(fitness_values[1:], 1):\n",
    "        if value < prev_value - 0.01:  \n",
    "            significant_points.append((i, value))\n",
    "            prev_value = value\n",
    "\n",
    "# Add markers at those points\n",
    "if significant_points:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[p[0] for p in significant_points],\n",
    "        y=[p[1] for p in significant_points],\n",
    "        mode='markers',\n",
    "        marker=dict(color='red', size=8, symbol='circle'),\n",
    "        name='Significant Improvements'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Fitness Progress Over Generations',\n",
    "    xaxis=dict(\n",
    "        title='Generation',\n",
    "        tickmode='linear',\n",
    "        tick0=0,\n",
    "        dtick=max(1, len(generations) // 20)  \n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Fitness (Loss)',\n",
    "        range=[max(0, min(fitness_values) - 0.1), min(max(fitness_values) + 0.1, 3.0)]\n",
    "    ),\n",
    "    hovermode='x unified',\n",
    "    template='plotly_white',\n",
    "    legend=dict(x=0.01, y=0.99, bgcolor='rgba(255,255,255,0.8)'),\n",
    "    margin=dict(l=20, r=20, t=60, b=20),\n",
    "    width=900,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "plateau_start = None\n",
    "for i in range(len(fitness_values) - 20): \n",
    "    window = fitness_values[i:i+20]\n",
    "    if max(window) - min(window) < 0.001:  \n",
    "        plateau_start = i\n",
    "        break\n",
    "\n",
    "if plateau_start is not None:\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=plateau_start, y0=min(fitness_values) - 0.1,\n",
    "        x1=plateau_start, y1=max(fitness_values) + 0.1,\n",
    "        line=dict(color=\"green\", width=2, dash=\"dash\"),\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=plateau_start, y=fitness_values[plateau_start],\n",
    "        text=\"Convergence plateau begins\",\n",
    "        showarrow=True,\n",
    "        arrowhead=1,\n",
    "    )\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Starting fitness: {fitness_values[0]:.6f}\")\n",
    "print(f\"Final fitness: {fitness_values[-1]:.6f}\")\n",
    "print(f\"Improvement: {fitness_values[0] - fitness_values[-1]:.6f} ({(fitness_values[0] - fitness_values[-1])/fitness_values[0]*100:.2f}%)\")\n",
    "print(f\"Number of generations: {len(fitness_values)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162b051-e2ff-4ae4-b885-13fed999908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(best_solution, x_test, y_test):\n",
    "\n",
    "    # Get predictions\n",
    "    probabilities = forward_pass(x_test, best_solution)\n",
    "    predictions = tf.argmax(probabilities, axis=1)\n",
    "    true_labels = tf.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = tf.equal(predictions, true_labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_test, probabilities))\n",
    "    \n",
    "    print(f\"Test accuracy: {accuracy.numpy() * 100:.2f}%\")\n",
    "    print(f\"Test loss: {loss.numpy():.4f}\")\n",
    "    \n",
    "    return accuracy.numpy(), predictions.numpy(), probabilities.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71154d6d-7197-49b4-bc02-396d9698cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, pred , prob = evaluate_model(result, x_test,y_test_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8251d7-d298-4365-ab3b-1fb771771237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(x_test, y_test, predictions, probabilities, num_samples=5):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import random\n",
    "    \n",
    "    # Get random samples\n",
    "    indices = random.sample(range(len(x_test)), num_samples)\n",
    "    \n",
    "    # Set up the figure\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, 2*num_samples))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        # Original image\n",
    "        original_image = x_test[idx].numpy().reshape(28, 28)\n",
    "        true_label = np.argmax(y_test[idx])\n",
    "        pred_label = predictions[idx]\n",
    "        pred_prob = probabilities[idx][pred_label]\n",
    "        \n",
    "        # Show image\n",
    "        axes[i, 0].imshow(original_image, cmap='gray')\n",
    "        axes[i, 0].set_title(f\"True: {true_label}\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Show probabilities\n",
    "        axes[i, 1].bar(range(10), probabilities[idx])\n",
    "        axes[i, 1].set_title(f\"Pred: {pred_label} (Confidence: {pred_prob:.4f})\")\n",
    "        axes[i, 1].set_xticks(range(10))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c582c31-2114-4d8f-a851-485d673a630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(x_test, y_test_hot,pred,prob,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebecf88-cf7a-473d-b662-c8562da05ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

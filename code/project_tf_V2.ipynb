{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e6ff7d-cf32-4ac3-a5d6-ac81c8d0fa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 02:34:48.104985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745454888.177342    5286 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745454888.196349    5286 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-24 02:34:48.325611: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21366e2b-aeba-4d49-a799-b3314a3e4c61",
   "metadata": {},
   "source": [
    "# loading data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b10e9fb-5b03-4882-b7be-9ab15c0ed301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images train before normalize and processing (60000, 28, 28)\n",
      "images train after reshaping (60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745454892.449730    5286 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2169 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 784\n",
    "HIDDEN_SIZE = 32\n",
    "OUTPUT_SIZE = 10\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "(x_train,y_train),(x_test, y_test) = mnist.load_data()\n",
    "print(\"images train before normalize and processing\",x_train.shape)\n",
    "\n",
    "x_train = tf.reshape(x_train, [-1, 28*28])\n",
    "x_test = tf.reshape(x_test, [-1, 28*28])\n",
    "\n",
    "print(\"images train after reshaping\",x_train.shape)\n",
    "# x_train[1]\n",
    "\n",
    "# handling pixels to be only black and white from gray scale\n",
    "x_train = tf.cast(x_train, tf.float32) / 255.0\n",
    "x_test = tf.cast(x_test, tf.float32) / 255.0\n",
    "\n",
    "\n",
    "y_train_hot = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_hot = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "print(y_train_hot.shape)\n",
    "print(y_test_hot.shape)\n",
    "\n",
    "y_train_hot = tf.convert_to_tensor(y_train_hot, dtype=tf.float32)\n",
    "y_test_hot = tf.convert_to_tensor(y_test_hot, dtype=tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571986e8-327a-4156-8c72-5337733790f6",
   "metadata": {},
   "source": [
    "# neural netowrk structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec15469-18ff-4097-bffe-0e8c36b2e356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac4c9f2-a658-4d18-b224-6ae365ab20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 784\n",
    "HIDDEN_SIZE = 32\n",
    "OUTPUT_SIZE = 10\n",
    "\n",
    "def sigmoid(x):\n",
    "    return tf.nn.sigmoid(x)\n",
    "\n",
    "def softmax(x):\n",
    "    return tf.nn.softmax(x)\n",
    "\n",
    "w1_size = INPUT_SIZE * HIDDEN_SIZE\n",
    "b1_size = HIDDEN_SIZE\n",
    "w2_size = HIDDEN_SIZE * OUTPUT_SIZE\n",
    "b2_size = OUTPUT_SIZE\n",
    "D = w1_size + b1_size + w2_size + b2_size\n",
    "\n",
    "\n",
    "def decode_weights(vector):\n",
    "    \n",
    "    w1_size = INPUT_SIZE * HIDDEN_SIZE\n",
    "    b1_size = HIDDEN_SIZE\n",
    "    w2_size = HIDDEN_SIZE * OUTPUT_SIZE\n",
    "    b2_size = OUTPUT_SIZE\n",
    "    \n",
    "    idx = 0\n",
    "    w1 = tf.reshape(vector[idx:idx + w1_size], [INPUT_SIZE, HIDDEN_SIZE])\n",
    "    idx += w1_size\n",
    "    \n",
    "    b1 = vector[idx:idx + b1_size]\n",
    "    idx += b1_size\n",
    "    \n",
    "    w2 = tf.reshape(vector[idx:idx + w2_size], [HIDDEN_SIZE, OUTPUT_SIZE])\n",
    "    idx += w2_size\n",
    "    \n",
    "    b2 = vector[idx:idx + b2_size]\n",
    "    \n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "\n",
    "def forward_pass(X, vector):\n",
    "    w1, b1, w2, b2 = decode_weights(vector)\n",
    "    \n",
    "    hidden = sigmoid(tf.matmul(X, w1) + b1)\n",
    "    output = softmax(tf.matmul(hidden, w2) + b2)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def fitness(vector, X, y_true, batch_size=1000):\n",
    "    \n",
    "    indices = np.random.choice(X.shape[0], batch_size, replace=False)\n",
    "    X_batch = tf.gather(X, indices)\n",
    "    y_batch = tf.gather(y_true, indices)\n",
    "    \n",
    "    y_pred = forward_pass(X_batch, vector)\n",
    "    loss = tf.keras.losses.categorical_crossentropy(y_batch, y_pred)\n",
    "    return tf.reduce_mean(loss)\n",
    "    \n",
    "# def fitness(vector, X, y_true):\n",
    "#     y_pred = forward_pass(X, vector)\n",
    "    \n",
    "#     loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    \n",
    "#     return tf.reduce_mean(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b994a81c-fce3-47ee-9c75-f05198ffff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 2.3042843341827393\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "total_weights = INPUT_SIZE * HIDDEN_SIZE + HIDDEN_SIZE + HIDDEN_SIZE * OUTPUT_SIZE + OUTPUT_SIZE\n",
    "vector_np = np.random.randn(total_weights) * 0.01\n",
    "vector_tf = tf.convert_to_tensor(vector_np, dtype=tf.float32)\n",
    "\n",
    "loss = fitness(vector_tf, x_train, y_train_hot)\n",
    "print(f\"Initial loss: {loss.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3666874b-ec79-4d7b-a0bf-a440b077524b",
   "metadata": {},
   "source": [
    "# functions for the DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf65eb9-246b-4f92-8257-d851c66485b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(24)\n",
    "tf.random.set_seed(24)\n",
    "\n",
    "def initialize_population(population_size, D, min_val=-0.5, max_val=0.5):\n",
    "    \n",
    "\n",
    "    population = tf.random.uniform(\n",
    "        shape=(population_size, D),\n",
    "        minval=min_val,\n",
    "        maxval=max_val,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    \n",
    "    return population\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061bb2db-b92e-4c15-bc04-73bf320dd4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(24)\n",
    "tf.random.set_seed(24)\n",
    "def random_vectors(population, current_index):\n",
    "\n",
    "    if isinstance(population, tf.Tensor):  # converts from tf to np\n",
    "        population_np = population.numpy()\n",
    "    else:\n",
    "        population_np = population\n",
    "    \n",
    "    population_size = population_np.shape[0]\n",
    "    \n",
    "    available_indices = np.delete(np.arange(population_size), current_index)\n",
    "    \n",
    "    selected_indices = np.random.choice(available_indices, size=3, replace=False)\n",
    "    \n",
    "    return (population_np[selected_indices[0]], \n",
    "            population_np[selected_indices[1]], \n",
    "            population_np[selected_indices[2]])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8d43956-410c-4440-97a0-130f8399aab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population shape is :  (100, 25450)\n"
     ]
    }
   ],
   "source": [
    "NP = 100\n",
    "\n",
    "population = initialize_population(population_size=NP ,D=D)\n",
    "print(\"population shape is : \",population.shape)\n",
    "\n",
    "v1, v2, v3 = random_vectors(population, 5)\n",
    "\n",
    "v1_tf = tf.convert_to_tensor(v1)\n",
    "v2_tf = tf.convert_to_tensor(v2)\n",
    "v3_tf = tf.convert_to_tensor(v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd878ab4-2c25-4e6a-ad2a-8114f630df8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25450])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3adc243-6b8a-4d6b-9fb5-204f893c42b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(x1, x2, x3, F, D, L=-1, H=1):\n",
    "\n",
    "    v = x3 + F * (x1 - x2)\n",
    "    \n",
    "    # ocnstrain handling\n",
    "    out_of_bounds = tf.logical_or(v < L, v > H) # returns tensor fo booleans where true is erorr\n",
    "    \n",
    "    random_values = L + tf.random.uniform(shape=(D,), dtype=tf.float32) * (H - L)\n",
    "    \n",
    "    v = tf.where(out_of_bounds, random_values, v) # checks where true and takes value from the random value if false takes from v\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5b25a-12cb-41fe-a0d3-b913aab48b3c",
   "metadata": {},
   "source": [
    " <p>example of how we did the mutate and how mask works</p>\n",
    "<img src=\"Screenshot_20250424_015153.png\" alt=\"Project Screenshot\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a81adb-cbd3-44d5-afdb-bd6814d2ca8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25450,)\n",
      "tf.Tensor(\n",
      "[-0.17597383  0.33066928 -0.13281165 ...  0.65596056 -0.09411368\n",
      "  0.33964458], shape=(25450,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "v = mutate(v1_tf, v2_tf, v3_tf, 0.9, D)\n",
    "print(v.shape)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ddbd642-d61c-43b1-8698-c203c45b2309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(target_vector, mutant_vector, CR, D):\n",
    "\n",
    "    # instead of loop and check we make the whole vecotor once and check with mask\n",
    "    r = tf.random.uniform(shape=(D,), dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    mask = r < CR  # mask is tensor flow boolean vecotr\n",
    "    \n",
    "    trial_vector = tf.where(mask, mutant_vector, target_vector)\n",
    "    \n",
    "    return trial_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c4daf-841a-4da9-b657-d87912202471",
   "metadata": {},
   "source": [
    "# main evolve function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97352aa1-cb47-4930-a18d-8a4404846b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve(population, GEN, NP, D, F, CR, x_train, y_train, L=-0.5, H=0.5):\n",
    "\n",
    "    best_solution = None\n",
    "    best_overall_fitness = float('inf')  # infinity for minimization\n",
    "    \n",
    "    \n",
    "    for g in range(GEN):\n",
    "        \n",
    "        for j in range(NP):\n",
    "            \n",
    "            v1, v2, v3 = random_vectors(population, j)\n",
    "            \n",
    "\n",
    "            v1 = tf.convert_to_tensor(v1, dtype=tf.float32)\n",
    "            v2 = tf.convert_to_tensor(v2, dtype=tf.float32)\n",
    "            v3 = tf.convert_to_tensor(v3, dtype=tf.float32)\n",
    "        \n",
    "            # mutation\n",
    "            mutant_child = mutate(v1, v2, v3, F, D, L, H)\n",
    "            \n",
    "            target_vector = population[j]\n",
    "            if not isinstance(target_vector, tf.Tensor):\n",
    "                target_vector = tf.convert_to_tensor(target_vector, dtype=tf.float32)\n",
    "            \n",
    "            # crossover\n",
    "            trial_vector = crossover(target_vector, mutant_child, CR, D)\n",
    "            \n",
    "            # fitness\n",
    "            trial_fitness = fitness(trial_vector, x_train, y_train  )\n",
    "            target_fitness = fitness(target_vector,x_train, y_train )\n",
    "            \n",
    "        \n",
    "            if trial_fitness < target_fitness:  \n",
    "                population[j].assign(trial_vector)  \n",
    "        \n",
    "        best_fitness = float('inf')\n",
    "        best_index = 0\n",
    "        for i in range(NP):\n",
    "            current_fitness = fitness(population[i],x_train, y_train )\n",
    "            if current_fitness < best_fitness:  \n",
    "                best_fitness = current_fitness\n",
    "                best_index = i\n",
    "                \n",
    "            if current_fitness < best_overall_fitness:  \n",
    "                best_overall_fitness = current_fitness\n",
    "                best_solution = tf.identity(population[i])  \n",
    "                \n",
    "        print(f\"Generation {g}: Best fitness (loss) = {best_fitness}\")\n",
    "    \n",
    "    return best_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce021220-f90f-4eb5-a873-77b8895930ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: Best fitness (loss) = 2.3856887817382812\n",
      "Generation 1: Best fitness (loss) = 2.3434674739837646\n",
      "Generation 2: Best fitness (loss) = 2.397263288497925\n",
      "Generation 3: Best fitness (loss) = 2.4033985137939453\n",
      "Generation 4: Best fitness (loss) = 2.401360034942627\n",
      "Generation 5: Best fitness (loss) = 2.4251039028167725\n",
      "Generation 6: Best fitness (loss) = 2.3919858932495117\n",
      "Generation 7: Best fitness (loss) = 2.3759944438934326\n",
      "Generation 8: Best fitness (loss) = 2.3865060806274414\n",
      "Generation 9: Best fitness (loss) = 2.4070234298706055\n",
      "Generation 10: Best fitness (loss) = 2.404425859451294\n",
      "Generation 11: Best fitness (loss) = 2.406125545501709\n",
      "Generation 12: Best fitness (loss) = 2.4003679752349854\n",
      "Generation 13: Best fitness (loss) = 2.4121792316436768\n",
      "Generation 14: Best fitness (loss) = 2.4267470836639404\n",
      "Generation 15: Best fitness (loss) = 2.385441541671753\n",
      "Generation 16: Best fitness (loss) = 2.383615732192993\n",
      "Generation 17: Best fitness (loss) = 2.387791395187378\n",
      "Generation 18: Best fitness (loss) = 2.4206783771514893\n",
      "Generation 19: Best fitness (loss) = 2.375775098800659\n",
      "Generation 20: Best fitness (loss) = 2.4156222343444824\n",
      "Generation 21: Best fitness (loss) = 2.3479089736938477\n",
      "Generation 22: Best fitness (loss) = 2.3872499465942383\n",
      "Generation 23: Best fitness (loss) = 2.4163119792938232\n",
      "Generation 24: Best fitness (loss) = 2.399244785308838\n",
      "Generation 25: Best fitness (loss) = 2.3825738430023193\n",
      "Generation 26: Best fitness (loss) = 2.3953897953033447\n",
      "Generation 27: Best fitness (loss) = 2.414886713027954\n",
      "Generation 28: Best fitness (loss) = 2.377980947494507\n",
      "Generation 29: Best fitness (loss) = 2.359819173812866\n",
      "Generation 30: Best fitness (loss) = 2.4155490398406982\n",
      "Generation 31: Best fitness (loss) = 2.3892459869384766\n",
      "Generation 32: Best fitness (loss) = 2.414262533187866\n",
      "Generation 33: Best fitness (loss) = 2.421635389328003\n",
      "Generation 34: Best fitness (loss) = 2.385934352874756\n",
      "Generation 35: Best fitness (loss) = 2.396409749984741\n",
      "Generation 36: Best fitness (loss) = 2.369436025619507\n",
      "Generation 37: Best fitness (loss) = 2.3729984760284424\n",
      "Generation 38: Best fitness (loss) = 2.4068453311920166\n",
      "Generation 39: Best fitness (loss) = 2.378943920135498\n",
      "Generation 40: Best fitness (loss) = 2.386941909790039\n",
      "Generation 41: Best fitness (loss) = 2.378246307373047\n",
      "Generation 42: Best fitness (loss) = 2.3915345668792725\n",
      "Generation 43: Best fitness (loss) = 2.3946452140808105\n",
      "Generation 44: Best fitness (loss) = 2.359400749206543\n",
      "Generation 45: Best fitness (loss) = 2.3582258224487305\n",
      "Generation 46: Best fitness (loss) = 2.3767521381378174\n",
      "Generation 47: Best fitness (loss) = 2.3660781383514404\n",
      "Generation 48: Best fitness (loss) = 2.364179849624634\n",
      "Generation 49: Best fitness (loss) = 2.387458086013794\n",
      "Generation 50: Best fitness (loss) = 2.4001054763793945\n",
      "Generation 51: Best fitness (loss) = 2.4044575691223145\n",
      "Generation 52: Best fitness (loss) = 2.373051643371582\n",
      "Generation 53: Best fitness (loss) = 2.360919713973999\n",
      "Generation 54: Best fitness (loss) = 2.3590517044067383\n",
      "Generation 55: Best fitness (loss) = 2.380544900894165\n",
      "Generation 56: Best fitness (loss) = 2.3834118843078613\n",
      "Generation 57: Best fitness (loss) = 2.363374710083008\n",
      "Generation 58: Best fitness (loss) = 2.401076316833496\n",
      "Generation 59: Best fitness (loss) = 2.3981621265411377\n",
      "Generation 60: Best fitness (loss) = 2.393787145614624\n",
      "Generation 61: Best fitness (loss) = 2.3906638622283936\n",
      "Generation 62: Best fitness (loss) = 2.402787208557129\n",
      "Generation 63: Best fitness (loss) = 2.3915810585021973\n",
      "Generation 64: Best fitness (loss) = 2.374509334564209\n",
      "Generation 65: Best fitness (loss) = 2.3888039588928223\n",
      "Generation 66: Best fitness (loss) = 2.3895370960235596\n",
      "Generation 67: Best fitness (loss) = 2.3964767456054688\n",
      "Generation 68: Best fitness (loss) = 2.408512592315674\n",
      "Generation 69: Best fitness (loss) = 2.3807404041290283\n",
      "Generation 70: Best fitness (loss) = 2.403454065322876\n",
      "Generation 71: Best fitness (loss) = 2.389143943786621\n",
      "Generation 72: Best fitness (loss) = 2.39992618560791\n",
      "Generation 73: Best fitness (loss) = 2.3967936038970947\n",
      "Generation 74: Best fitness (loss) = 2.3749606609344482\n",
      "Generation 75: Best fitness (loss) = 2.3814759254455566\n",
      "Generation 76: Best fitness (loss) = 2.3852579593658447\n",
      "Generation 77: Best fitness (loss) = 2.3832626342773438\n",
      "Generation 78: Best fitness (loss) = 2.402773857116699\n",
      "Generation 79: Best fitness (loss) = 2.392681837081909\n",
      "Generation 80: Best fitness (loss) = 2.4091224670410156\n",
      "Generation 81: Best fitness (loss) = 2.392519235610962\n",
      "Generation 82: Best fitness (loss) = 2.378082275390625\n",
      "Generation 83: Best fitness (loss) = 2.413137674331665\n",
      "Generation 84: Best fitness (loss) = 2.4025142192840576\n",
      "Generation 85: Best fitness (loss) = 2.4073402881622314\n",
      "Generation 86: Best fitness (loss) = 2.381382465362549\n",
      "Generation 87: Best fitness (loss) = 2.4097647666931152\n",
      "Generation 88: Best fitness (loss) = 2.3559744358062744\n",
      "Generation 89: Best fitness (loss) = 2.398056983947754\n",
      "Generation 90: Best fitness (loss) = 2.389005184173584\n",
      "Generation 91: Best fitness (loss) = 2.4344780445098877\n",
      "Generation 92: Best fitness (loss) = 2.414783239364624\n",
      "Generation 93: Best fitness (loss) = 2.3978524208068848\n",
      "Generation 94: Best fitness (loss) = 2.3978612422943115\n",
      "Generation 95: Best fitness (loss) = 2.39953351020813\n",
      "Generation 96: Best fitness (loss) = 2.3865137100219727\n",
      "Generation 97: Best fitness (loss) = 2.404898166656494\n",
      "Generation 98: Best fitness (loss) = 2.351945400238037\n",
      "Generation 99: Best fitness (loss) = 2.3621206283569336\n",
      "Generation 100: Best fitness (loss) = 2.389167308807373\n",
      "Generation 101: Best fitness (loss) = 2.4012460708618164\n",
      "Generation 102: Best fitness (loss) = 2.4000353813171387\n",
      "Generation 103: Best fitness (loss) = 2.3862550258636475\n",
      "Generation 104: Best fitness (loss) = 2.4108059406280518\n",
      "Generation 105: Best fitness (loss) = 2.3546526432037354\n",
      "Generation 106: Best fitness (loss) = 2.389162540435791\n",
      "Generation 107: Best fitness (loss) = 2.407163143157959\n",
      "Generation 108: Best fitness (loss) = 2.39247727394104\n",
      "Generation 109: Best fitness (loss) = 2.368875741958618\n",
      "Generation 110: Best fitness (loss) = 2.3954415321350098\n",
      "Generation 111: Best fitness (loss) = 2.4040377140045166\n",
      "Generation 112: Best fitness (loss) = 2.397847890853882\n",
      "Generation 113: Best fitness (loss) = 2.402458667755127\n",
      "Generation 114: Best fitness (loss) = 2.3651115894317627\n",
      "Generation 115: Best fitness (loss) = 2.4064316749572754\n",
      "Generation 116: Best fitness (loss) = 2.3858838081359863\n",
      "Generation 117: Best fitness (loss) = 2.3758604526519775\n",
      "Generation 118: Best fitness (loss) = 2.394732713699341\n",
      "Generation 119: Best fitness (loss) = 2.3891053199768066\n",
      "Generation 120: Best fitness (loss) = 2.3908073902130127\n",
      "Generation 121: Best fitness (loss) = 2.3765487670898438\n",
      "Generation 122: Best fitness (loss) = 2.3902347087860107\n",
      "Generation 123: Best fitness (loss) = 2.3863604068756104\n",
      "Generation 124: Best fitness (loss) = 2.4242818355560303\n",
      "Generation 125: Best fitness (loss) = 2.385474443435669\n",
      "Generation 126: Best fitness (loss) = 2.40391206741333\n",
      "Generation 127: Best fitness (loss) = 2.3759233951568604\n",
      "Generation 128: Best fitness (loss) = 2.392329454421997\n",
      "Generation 129: Best fitness (loss) = 2.380185842514038\n",
      "Generation 130: Best fitness (loss) = 2.396763324737549\n",
      "Generation 131: Best fitness (loss) = 2.369594097137451\n",
      "Generation 132: Best fitness (loss) = 2.392648696899414\n",
      "Generation 133: Best fitness (loss) = 2.396674394607544\n",
      "Generation 134: Best fitness (loss) = 2.3803791999816895\n",
      "Generation 135: Best fitness (loss) = 2.4113047122955322\n",
      "Generation 136: Best fitness (loss) = 2.373119831085205\n",
      "Generation 137: Best fitness (loss) = 2.3897597789764404\n",
      "Generation 138: Best fitness (loss) = 2.381232500076294\n",
      "Generation 139: Best fitness (loss) = 2.3859071731567383\n",
      "Generation 140: Best fitness (loss) = 2.4020063877105713\n",
      "Generation 141: Best fitness (loss) = 2.3960585594177246\n",
      "Generation 142: Best fitness (loss) = 2.4099719524383545\n",
      "Generation 143: Best fitness (loss) = 2.4010987281799316\n",
      "Generation 144: Best fitness (loss) = 2.3496835231781006\n",
      "Generation 145: Best fitness (loss) = 2.3772239685058594\n",
      "Generation 146: Best fitness (loss) = 2.4210245609283447\n",
      "Generation 147: Best fitness (loss) = 2.3820321559906006\n",
      "Generation 148: Best fitness (loss) = 2.4060165882110596\n",
      "Generation 149: Best fitness (loss) = 2.378875255584717\n",
      "Generation 150: Best fitness (loss) = 2.4076695442199707\n"
     ]
    }
   ],
   "source": [
    "population = tf.Variable(population)\n",
    "result = evolve(population, 100, NP, D, 0.8, 0.7, x_train, y_train_hot, L=-1, H=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162b051-e2ff-4ae4-b885-13fed999908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(best_solution, x_test, y_test):\n",
    "\n",
    "    # Get predictions\n",
    "    probabilities = forward_pass(x_test, best_solution)\n",
    "    predictions = tf.argmax(probabilities, axis=1)\n",
    "    true_labels = tf.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = tf.equal(predictions, true_labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_test, probabilities))\n",
    "    \n",
    "    print(f\"Test accuracy: {accuracy.numpy() * 100:.2f}%\")\n",
    "    print(f\"Test loss: {loss.numpy():.4f}\")\n",
    "    \n",
    "    return accuracy.numpy(), predictions.numpy(), probabilities.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71154d6d-7197-49b4-bc02-396d9698cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, pred , prob = evaluate_model(result, x_test,y_test_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8251d7-d298-4365-ab3b-1fb771771237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(x_test, y_test, predictions, probabilities, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualize sample predictions from the model\n",
    "    \n",
    "    Args:\n",
    "        x_test: Test input data\n",
    "        y_test: Test labels (one-hot encoded)\n",
    "        predictions: Predicted classes\n",
    "        probabilities: Prediction probabilities\n",
    "        num_samples: Number of samples to visualize\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import random\n",
    "    \n",
    "    # Get random samples\n",
    "    indices = random.sample(range(len(x_test)), num_samples)\n",
    "    \n",
    "    # Set up the figure\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, 2*num_samples))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        # Original image\n",
    "        original_image = x_test[idx].numpy().reshape(28, 28)\n",
    "        true_label = np.argmax(y_test[idx])\n",
    "        pred_label = predictions[idx]\n",
    "        pred_prob = probabilities[idx][pred_label]\n",
    "        \n",
    "        # Show image\n",
    "        axes[i, 0].imshow(original_image, cmap='gray')\n",
    "        axes[i, 0].set_title(f\"True: {true_label}\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Show probabilities\n",
    "        axes[i, 1].bar(range(10), probabilities[idx])\n",
    "        axes[i, 1].set_title(f\"Pred: {pred_label} (Confidence: {pred_prob:.4f})\")\n",
    "        axes[i, 1].set_xticks(range(10))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c582c31-2114-4d8f-a851-485d673a630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(x_test, y_test_hot,pred,prob,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebecf88-cf7a-473d-b662-c8562da05ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
